import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from typing import Tuple, List, Dict
import glob
import os

class HVACDataProcessor:
    """HVAC ë¡œê·¸ ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤ - Auto IDë³„ 5ë¶„ ê°„ê²© ìƒ˜í”Œë§ ìˆ˜ì • ë²„ì „"""
    
    def __init__(self):
        self.state_scaler = StandardScaler()
        self.action_scaler = StandardScaler()
        
    def load_data(self, file_pattern: str) -> pd.DataFrame:
        """CSV íŒŒì¼ë“¤ì„ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œ"""
        files = glob.glob(file_pattern)
        files.sort()
        
        all_sequences = []
        
        for file in files:
            print(f"Processing {file}...")
            try:
                df = pd.read_csv(file)
                # ì‹œê°„ íŒŒì‹±
                try:
                    df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S')
                except:
                    df['Time'] = pd.to_datetime(df['Time'], errors='coerce')
                
                # NaT ê°’ ì œê±°
                df = df.dropna(subset=['Time'])
                
                if len(df) == 0:
                    print(f"  âš ï¸ No valid data in {file}")
                    continue
                
                # íŒŒì¼ ë‚´ì—ì„œ ì‹œê°„ìˆœ ì •ë ¬
                df = df.sort_values('Time').reset_index(drop=True)
                
                # Auto IDë³„ë¡œ 5ë¶„ ê°„ê²© ë¦¬ìƒ˜í”Œë§
                resampled_data = self.resample_by_auto_id(df)
                
                if len(resampled_data) > 0:
                    print(f"  âœ… {len(df)} â†’ {len(resampled_data)} rows (Auto IDë³„ 5ë¶„ ê°„ê²©)")
                    # íŒŒì¼ë³„ ì‹ë³„ì ì¶”ê°€
                    resampled_data['file_source'] = file
                    all_sequences.append(resampled_data)
                else:
                    print(f"  âš ï¸ No data after resampling in {file}")
                
            except Exception as e:
                print(f"  âŒ Error loading {file}: {e}")
                continue
        
        if not all_sequences:
            raise ValueError("No valid data found in any files")
        
        combined_df = pd.concat(all_sequences, ignore_index=True)
        
        print(f"âœ… Total processed: {len(combined_df)} rows from {len(all_sequences)} files")
        return combined_df
    
    def resample_by_auto_id(self, df: pd.DataFrame) -> pd.DataFrame:
        """Auto IDë³„ë¡œ 5ë¶„ ê°„ê²© ë¦¬ìƒ˜í”Œë§"""
        print(f"ğŸ”„ Auto IDë³„ 5ë¶„ ê°„ê²© ë¦¬ìƒ˜í”Œë§ ì‹œì‘...")
        
        # Auto IDë³„ë¡œ ê·¸ë£¹í™”
        auto_ids = df['Auto Id'].unique()
        print(f"   ë°œê²¬ëœ Auto ID: {sorted(auto_ids)}")
        
        resampled_groups = []
        
        for auto_id in auto_ids:
            auto_df = df[df['Auto Id'] == auto_id].copy()
            auto_df = auto_df.sort_values('Time').reset_index(drop=True)
            
            if len(auto_df) < 2:
                print(f"   Auto ID {auto_id}: ë°ì´í„° ë¶€ì¡± ({len(auto_df)}ê°œ) - ê±´ë„ˆëœ€")
                continue
            
            # ì‹œê°„ ê°„ê²© ë¶„ì„
            time_diff = auto_df['Time'].diff().dropna()
            if len(time_diff) > 0:
                median_interval = time_diff.median().total_seconds()
                print(f"   Auto ID {auto_id}: {len(auto_df)}ê°œ ë°ì´í„°, ì¤‘ê°„ê°’ ê°„ê²© {median_interval:.0f}ì´ˆ")
            
            # 5ë¶„(300ì´ˆ) ê°„ê²©ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§
            target_interval = pd.Timedelta(seconds=300)  # 5ë¶„
            
            # ì‹œì‘ ì‹œê°„ë¶€í„° 5ë¶„ ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§
            start_time = auto_df['Time'].iloc[0]
            end_time = auto_df['Time'].iloc[-1]
            
            # 5ë¶„ ê°„ê²© ì‹œê°„ ì¸ë±ìŠ¤ ìƒì„±
            time_index = pd.date_range(start=start_time, end=end_time, freq='5T')
            
            if len(time_index) < 2:
                print(f"   Auto ID {auto_id}: ì‹œê°„ ë²”ìœ„ ë¶€ì¡± - ê±´ë„ˆëœ€")
                continue
            
            # ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ì˜ ë°ì´í„° ì„ íƒ (nearest neighbor ë°©ì‹)
            resampled_rows = []
            
            for target_time in time_index:
                # ëª©í‘œ ì‹œê°„ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° ì°¾ê¸°
                time_diffs = np.abs((auto_df['Time'] - target_time).dt.total_seconds())
                closest_idx = time_diffs.idxmin()
                
                # 5ë¶„ ì´ë‚´ì˜ ë°ì´í„°ë§Œ ì‚¬ìš© (ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì§„ ë°ì´í„°ëŠ” ì œì™¸)
                if time_diffs.loc[closest_idx] <= 300:  # 5ë¶„ ì´ë‚´
                    resampled_rows.append(auto_df.loc[closest_idx])
            
            if len(resampled_rows) > 0:
                resampled_auto_df = pd.DataFrame(resampled_rows).reset_index(drop=True)
                # ì¤‘ë³µ ì œê±° (ê°™ì€ ì›ë³¸ ë°ì´í„°ê°€ ì—¬ëŸ¬ ë²ˆ ì„ íƒë  ìˆ˜ ìˆìŒ)
                resampled_auto_df = resampled_auto_df.drop_duplicates(subset='Time').reset_index(drop=True)
                resampled_groups.append(resampled_auto_df)
                print(f"   Auto ID {auto_id}: {len(auto_df)} â†’ {len(resampled_auto_df)}ê°œ (5ë¶„ ê°„ê²©)")
            else:
                print(f"   Auto ID {auto_id}: ë¦¬ìƒ˜í”Œë§ í›„ ë°ì´í„° ì—†ìŒ")
        
        if len(resampled_groups) == 0:
            print("   âš ï¸ ëª¨ë“  Auto IDì—ì„œ ë¦¬ìƒ˜í”Œë§ ì‹¤íŒ¨")
            return pd.DataFrame()
        
        # ëª¨ë“  Auto IDì˜ ë¦¬ìƒ˜í”Œë§ëœ ë°ì´í„° ê²°í•©
        result_df = pd.concat(resampled_groups, ignore_index=True)
        result_df = result_df.sort_values(['Time', 'Auto Id']).reset_index(drop=True)
        
        print(f"   âœ… ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ: ì´ {len(result_df)}ê°œ ë°ì´í„°")
        
        # Auto IDë³„ ìµœì¢… ë°ì´í„° ê°œìˆ˜ í™•ì¸
        final_counts = result_df['Auto Id'].value_counts().sort_index()
        print(f"   ğŸ“Š Auto IDë³„ ìµœì¢… ë°ì´í„°:")
        for auto_id, count in final_counts.items():
            print(f"      Auto ID {auto_id}: {count}ê°œ")
        
        return result_df
    
    def extract_features_simplified(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """ë‹¨ìˆœí™”ëœ íŠ¹ì„± ì¶”ì¶œ - í˜ì–´ë§ ì—†ì´ ê°œë³„ ì²˜ë¦¬"""
        
        print("ğŸ” ë‹¨ìˆœí™”ëœ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        print(f"ì „ì²´ ë°ì´í„° í¬ê¸°: {df.shape}")
        print(f"Auto Id ë²”ìœ„: {df['Auto Id'].min()} ~ {df['Auto Id'].max()}")
        print(f"ê³ ìœ  Auto Id ê°œìˆ˜: {df['Auto Id'].nunique()}")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ í™•ì¸ - Power ì œì™¸
        required_state_cols = ['Tpip_in', 'Tpip_out', 'Tbdy', 'Tid', 'Tod']  # Power ì œê±°
        required_action_cols = ['Tcon']
        
        available_state_cols = [col for col in required_state_cols if col in df.columns]
        available_action_cols = [col for col in required_action_cols if col in df.columns]
        
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ State ì»¬ëŸ¼ (Power ì œì™¸): {available_state_cols}")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ Action ì»¬ëŸ¼: {available_action_cols}")
        print(f"ğŸ“ PowerëŠ” ì¸¡ì • ì£¼ê¸°ê°€ ë‹¬ë¼ World Modelì—ì„œ ì œì™¸ë¨")
        
        if not available_state_cols or not available_action_cols:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. State: {available_state_cols}, Action: {available_action_cols}")
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬ - ì¼ë°˜ì ì¸ ë°©ì‹ìœ¼ë¡œ ë‹¨ìˆœí™”
        df_clean = df[available_state_cols + available_action_cols + ['file_source', 'Auto Id', 'Time']].copy()
        df_clean = df_clean.fillna(method='ffill').fillna(0)
        
        # State íŠ¹ì„± (ê°œë³„ ì—ì–´ì»¨)
        states = df_clean[available_state_cols].values
        
        # Action íŠ¹ì„± ìƒì„±
        tcon_values = df_clean[available_action_cols].values
        
        # on/off íŠ¹ì„± (Tconì´ 0ì´ ì•„ë‹ˆë©´ 1)
        on_off = (tcon_values != 0).astype(int)
        
        # Ptarget (ëª©í‘œ ì••ë ¥) - ê¸°ë³¸ê°’
        ptarget = np.full((len(tcon_values), 1), 25.0)
        
        # Action ê²°í•©: [Tcon, on/off, Ptarget]
        actions = np.hstack([tcon_values, on_off, ptarget])
        
        # íŒŒì¼ ì†ŒìŠ¤ ì •ë³´ (Auto IDì™€ ì‹œê°„ ì •ë³´ í¬í•¨)
        file_sources = df_clean.apply(lambda row: f"{row['file_source']}_AutoID_{row['Auto Id']}", axis=1).values
        
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   States shape: {states.shape}")
        print(f"   Actions shape: {actions.shape}")
        print(f"   File sources: {len(set(file_sources))}ê°œ ê³ ìœ  ì‹œí€€ìŠ¤")
        
        return states, actions, file_sources
    
    def extract_features_paired(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """ì—ì–´ì»¨ ìŒìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” íŠ¹ì„± ì¶”ì¶œ - 5ë¶„ ê°„ê²© ë°ì´í„° ê¸°ë°˜"""
        
        print("ğŸ” í˜ì–´ë§ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        print(f"ì „ì²´ ë°ì´í„° í¬ê¸°: {df.shape}")
        
        # Auto Id ë¶„ì„
        auto_ids = df['Auto Id'].unique()
        print(f"Auto Id ë²”ìœ„: {auto_ids.min()} ~ {auto_ids.max()}")
        print(f"ê³ ìœ  Auto Id: {sorted(auto_ids)}")
        
        # AC_Pairì™€ AC_Unit ê³„ì‚°
        df['AC_Pair'] = (df['Auto Id'] + 1) // 2
        df['AC_Unit'] = (df['Auto Id'] % 2) + 1
        
        pair_unit_counts = df.groupby(['AC_Pair', 'AC_Unit']).size().unstack(fill_value=0)
        print(f"AC_Pairë³„ Unit ë¶„í¬:")
        print(pair_unit_counts)
        
        # í˜ì–´ë§ ê°€ëŠ¥í•œ AC_Pair ì°¾ê¸°
        paired_acs = pair_unit_counts[(pair_unit_counts[1] > 0) & (pair_unit_counts[2] > 0)].index
        print(f"í˜ì–´ë§ ê°€ëŠ¥í•œ AC_Pair: {list(paired_acs)}")
        
        if len(paired_acs) == 0:
            print("âš ï¸ í˜ì–´ë§ ê°€ëŠ¥í•œ ACê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¨ìˆœí™”ëœ ë°©ì‹ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            return self.extract_features_simplified(df)
        
        # í˜ì–´ë§ëœ ë°ì´í„° ìƒì„± - 5ë¶„ ê°„ê²© ë°ì´í„° ê¸°ë°˜
        grouped_data = []
        file_sources = []
        
        for pair_id in paired_acs:
            pair_data = df[df['AC_Pair'] == pair_id].copy()
            
            # ì‹œê°„ë³„ë¡œ ê·¸ë£¹í™” (5ë¶„ ê°„ê²©ìœ¼ë¡œ ì´ë¯¸ ë¦¬ìƒ˜í”Œë§ëœ ë°ì´í„°)
            time_groups = pair_data.groupby('Time')
            
            pair_matches = 0
            for time, group in time_groups:
                group_1 = group[group['AC_Unit'] == 1]
                group_2 = group[group['AC_Unit'] == 2]
                
                if len(group_1) > 0 and len(group_2) > 0:
                    unit1 = group_1.iloc[0]
                    unit2 = group_2.iloc[0]
                    
                    # State íŠ¹ì„± ì¶”ì¶œ (ì•ˆì „í•œ ë°©ì‹)
                    def safe_get(row, col, default=0.0):
                        val = row.get(col, default)
                        if pd.isna(val) or val is None:
                            return float(default)
                        return float(val)
                    
                    state_features = [
                        safe_get(unit1, 'Tpip_in'), safe_get(unit2, 'Tpip_in'),
                        safe_get(unit1, 'Tpip_out'), safe_get(unit2, 'Tpip_out'),
                        safe_get(unit1, 'Tbdy'), safe_get(unit2, 'Tbdy'),
                        safe_get(unit1, 'Tid'), safe_get(unit2, 'Tid'),
                        safe_get(unit1, 'Tod')  # TodëŠ” ê³µí†µ, Power ì œê±°
                    ]
                    
                    # Action íŠ¹ì„± ì¶”ì¶œ
                    tcon1 = safe_get(unit1, 'Tcon')
                    tcon2 = safe_get(unit2, 'Tcon')
                    
                    action_features = [
                        tcon1, tcon2,
                        1 if tcon1 != 0 else 0,  # on/off1
                        1 if tcon2 != 0 else 0,  # on/off2
                        25.0  # Ptarget
                    ]
                    
                    grouped_data.append({
                        'time': time,
                        'pair_id': pair_id,
                        'states': state_features,
                        'actions': action_features
                    })
                    
                    file_sources.append(f"{unit1.get('file_source', 'unknown')}_Pair_{pair_id}")
                    pair_matches += 1
            
            print(f"  AC_Pair {pair_id}: {pair_matches}ê°œ ë§¤ì¹­ëœ ì‹œì  (5ë¶„ ê°„ê²©)")
        
        if not grouped_data:
            print("âš ï¸ ë§¤ì¹­ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¨ìˆœí™”ëœ ë°©ì‹ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            return self.extract_features_simplified(df)
        
        states = np.array([item['states'] for item in grouped_data])
        actions = np.array([item['actions'] for item in grouped_data])
        file_sources = np.array(file_sources)
        
        print(f"âœ… í˜ì–´ë§ ì™„ë£Œ: {len(states)}ê°œ ìƒ˜í”Œ (5ë¶„ ê°„ê²©)")
        print(f"   States shape: {states.shape}")
        print(f"   Actions shape: {actions.shape}")
        
        return states, actions, file_sources
    
    def extract_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """ë©”ì¸ íŠ¹ì„± ì¶”ì¶œ í•¨ìˆ˜ - í˜ì–´ë§ ì‹œë„ í›„ ì‹¤íŒ¨ì‹œ ë‹¨ìˆœí™” ë°©ì‹"""
        try:
            return self.extract_features_paired(df)
        except Exception as e:
            print(f"âš ï¸ í˜ì–´ë§ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            print("ë‹¨ìˆœí™”ëœ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
            return self.extract_features_simplified(df)
    
    def create_sequences_per_auto_id(self, states: np.ndarray, actions: np.ndarray, 
                                    file_sources: np.ndarray, seq_length: int = 10, 
                                    prediction_horizon: int = 3) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Auto IDë³„ë¡œ ë…ë¦½ì ì¸ ì‹œí€€ìŠ¤ ìƒì„± - ë” ê¸´ ì˜ˆì¸¡ ê°„ê²©ìœ¼ë¡œ ìˆ˜ì •"""
        
        # ì •ê·œí™”
        states_normalized = self.state_scaler.fit_transform(states)
        actions_normalized = self.action_scaler.fit_transform(actions)
        
        X_states, X_actions, y_states = [], [], []
        
        # Auto ID/íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”
        unique_sources = np.unique(file_sources)
        print(f"ğŸ“ Auto IDë³„ ì‹œí€€ìŠ¤ ìƒì„±: {len(unique_sources)}ê°œ ê³ ìœ  ì‹œí€€ìŠ¤")
        print(f"ğŸ¯ ì˜ˆì¸¡ ê°„ê²©: {prediction_horizon}ìŠ¤í… ({prediction_horizon * 5}ë¶„ í›„ ì˜ˆì¸¡)")
        
        for source_name in unique_sources:
            # ì•ˆì „í•œ ì†ŒìŠ¤ëª… ì²˜ë¦¬
            try:
                source_display_name = str(source_name)
                if '\\' in source_display_name:
                    source_display_name = source_display_name.split('\\')[-1]
                elif '/' in source_display_name:
                    source_display_name = source_display_name.split('/')[-1]
            except:
                source_display_name = f"source_{hash(str(source_name)) % 1000}"
            
            source_mask = file_sources == source_name
            source_states = states_normalized[source_mask]
            source_actions = actions_normalized[source_mask]
            
            # ê° Auto ID/íŒŒì¼ ë‚´ì—ì„œë§Œ ì‹œí€€ìŠ¤ ìƒì„± (ë” ê¸´ ì˜ˆì¸¡ ê°„ê²©)
            source_sequences = 0
            if len(source_states) > seq_length + prediction_horizon:
                for i in range(len(source_states) - seq_length - prediction_horizon):
                    X_states.append(source_states[i:i+seq_length])
                    X_actions.append(source_actions[i:i+seq_length])
                    # prediction_horizon ìŠ¤í… í›„ì˜ ìƒíƒœë¥¼ ì˜ˆì¸¡ (ë” ì–´ë ¤ìš´ ì˜ˆì¸¡)
                    y_states.append(source_states[i+seq_length+prediction_horizon-1])
                    source_sequences += 1
            
            print(f"  {source_display_name}: {len(source_states)} rows â†’ {source_sequences} sequences")
        
        if len(X_states) == 0:
            raise ValueError("ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        
        print(f"âœ… ì´ {len(X_states)}ê°œ ì‹œí€€ìŠ¤ ìƒì„± (Auto IDë³„ ë…ë¦½ì , {prediction_horizon * 5}ë¶„ í›„ ì˜ˆì¸¡)")
        
        return np.array(X_states), np.array(X_actions), np.array(y_states)

class HVACDataset(Dataset):
    """PyTorch Dataset í´ë˜ìŠ¤"""
    
    def __init__(self, states: np.ndarray, actions: np.ndarray, targets: np.ndarray):
        self.states = torch.FloatTensor(states)
        self.actions = torch.FloatTensor(actions)
        self.targets = torch.FloatTensor(targets)
        
    def __len__(self):
        return len(self.states)
    
    def __getitem__(self, idx):
        return self.states[idx], self.actions[idx], self.targets[idx]

class SimpleSSMWorldModel(nn.Module):
    """ë‹¨ìˆœí™”ëœ SSM World Model"""
    
    def __init__(self, state_dim: int, action_dim: int, hidden_dim: int = 64, 
                 latent_dim: int = 32):
        super(SimpleSSMWorldModel, self).__init__()
        
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.hidden_dim = hidden_dim
        self.latent_dim = latent_dim
        
        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(state_dim + action_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, latent_dim)
        )
        
        # State Space Model
        self.state_transition = nn.Sequential(
            nn.Linear(latent_dim + action_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, latent_dim)
        )
        
        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, state_dim)
        )
        
        # ì‹œê°„ì  ê°€ì¤‘ì¹˜
        self.temporal_weight = nn.Parameter(torch.tensor(0.8))
        
    def forward(self, states: torch.Tensor, actions: torch.Tensor) -> torch.Tensor:
        """ìˆœì „íŒŒ"""
        batch_size, seq_len, _ = states.shape
        
        # ìµœê·¼ ëª‡ ê°œ ì‹œì ë§Œ ì‚¬ìš©
        use_seq_len = min(3, seq_len)
        recent_states = states[:, -use_seq_len:]
        recent_actions = actions[:, -use_seq_len:]
        
        # ê° ì‹œì  ì¸ì½”ë”©
        encoded_features = []
        for t in range(use_seq_len):
            combined = torch.cat([recent_states[:, t], recent_actions[:, t]], dim=-1)
            encoded = self.encoder(combined)
            encoded_features.append(encoded)
        
        # ê°€ì¤‘ í‰ê· 
        if use_seq_len == 1:
            final_encoded = encoded_features[0]
        else:
            weights = torch.softmax(torch.linspace(0.1, 1.0, use_seq_len).to(states.device), dim=0)
            final_encoded = sum(w * enc for w, enc in zip(weights, encoded_features))
        
        # State transition
        last_action = recent_actions[:, -1]
        transition_input = torch.cat([final_encoded, last_action], dim=-1)
        next_latent = self.state_transition(transition_input)
        
        # ì‹œê°„ì  ì—°ì†ì„±
        temporal_factor = torch.sigmoid(self.temporal_weight)
        last_state = recent_states[:, -1]
        
        # ë””ì½”ë”©
        decoded_change = self.decoder(next_latent)
        
        # ì ì§„ì  ë³€í™”
        predicted_state = temporal_factor * last_state + (1 - temporal_factor) * decoded_change
        
        return predicted_state
    
    def predict_next_state(self, current_state: torch.Tensor, action: torch.Tensor) -> torch.Tensor:
        """ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡"""
        with torch.no_grad():
            if len(current_state.shape) == 1:
                current_state = current_state.unsqueeze(0)
            if len(action.shape) == 1:
                action = action.unsqueeze(0)
                
            state_seq = current_state.unsqueeze(1)
            action_seq = action.unsqueeze(1)
            
            prediction = self.forward(state_seq, action_seq)
            
            return prediction.squeeze(0) if prediction.shape[0] == 1 else prediction

class SSMTrainer:
    """SSM World Model í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, model: SimpleSSMWorldModel, learning_rate: float = 0.001):
        self.model = model
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', patience=3, factor=0.7)
        self.criterion = nn.MSELoss()
        self.train_losses = []
        self.val_losses = []
        
    def train_epoch(self, train_loader: DataLoader) -> float:
        """í•œ ì—í¬í¬ í›ˆë ¨"""
        self.model.train()
        total_loss = 0.0
        
        for states, actions, targets in train_loader:
            self.optimizer.zero_grad()
            predictions = self.model(states, actions)
            loss = self.criterion(predictions, targets)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.1)
            self.optimizer.step()
            total_loss += loss.item()
            
        return total_loss / len(train_loader)
    
    def validate(self, val_loader: DataLoader) -> float:
        """ê²€ì¦"""
        self.model.eval()
        total_loss = 0.0
        
        with torch.no_grad():
            for states, actions, targets in val_loader:
                predictions = self.model(states, actions)
                loss = self.criterion(predictions, targets)
                total_loss += loss.item()
                
        return total_loss / len(val_loader)
    
    def train(self, train_loader: DataLoader, val_loader: DataLoader, 
              epochs: int = 50, patience: int = 10) -> Dict:
        """ì „ì²´ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤"""
        best_val_loss = float('inf')
        patience_counter = 0
        min_improvement = 1e-4
        
        for epoch in range(epochs):
            train_loss = self.train_epoch(train_loader)
            val_loss = self.validate(val_loader)
            self.scheduler.step(val_loss)
            
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            
            current_lr = self.optimizer.param_groups[0]['lr']
            improvement = best_val_loss - val_loss
            
            print(f"Epoch {epoch+1:2d}/{epochs} - Train: {train_loss:.4f}, Val: {val_loss:.4f}, "
                  f"LR: {current_lr:.1e}, Gap: {val_loss-train_loss:.4f}")
            
            if improvement > min_improvement:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(self.model.state_dict(), 'best_simple_ssm_model.pth')
                print(f"    âœ“ New best! Improvement: {improvement:.4f}")
            else:
                patience_counter += 1
                print(f"    No improvement ({patience_counter}/{patience})")
                
            if patience_counter >= patience:
                print(f"Early stopping at epoch {epoch+1}")
                break
                
            if val_loss - train_loss > 0.5:
                print(f"Overfitting detected! Gap: {val_loss - train_loss:.4f}")
                break
                
        return {
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'best_val_loss': best_val_loss
        }
    
    def plot_losses(self):
        """ì†ì‹¤ ê·¸ë˜í”„ ì‹œê°í™”"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            save_path = 'training_progress.png'
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
            
            # ì²« ë²ˆì§¸ ì„œë¸Œí”Œë¡¯: ì†ì‹¤ ê³¡ì„ 
            ax1.plot(self.train_losses, label='Training Loss', color='blue', linewidth=2, marker='o', markersize=3)
            ax1.plot(self.val_losses, label='Validation Loss', color='red', linewidth=2, marker='s', markersize=3)
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            ax1.set_title('Training Progress (Auto IDë³„ 5ë¶„ ê°„ê²© ìƒ˜í”Œë§)', fontsize=14, fontweight='bold')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            ax1.set_yscale('log')
            
            # ë‘ ë²ˆì§¸ ì„œë¸Œí”Œë¡¯: ê³¼ì í•© ëª¨ë‹ˆí„°
            gaps = [val - train for train, val in zip(self.train_losses, self.val_losses)]
            ax2.plot(gaps, label='Val - Train Gap', color='orange', linewidth=2, marker='^', markersize=3)
            ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Loss Gap')
            ax2.set_title('Overfitting Monitor (Gap should be close to 0)', fontsize=14, fontweight='bold')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
            
            if os.path.exists(save_path) and os.path.getsize(save_path) > 0:
                print(f"âœ… Training progress saved as '{save_path}'")
                print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(save_path)} bytes")
            else:
                print("âŒ ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨")
                
            plt.close()
            
        except Exception as e:
            print(f"âŒ ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
            print("ì†ì‹¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤:")
            print(f"í›ˆë ¨ ì†ì‹¤: {self.train_losses}")
            print(f"ê²€ì¦ ì†ì‹¤: {self.val_losses}")
    
    def create_validation_plots(self, model, test_loader, processor, num_steps=10):
        """ìŠ¤í…ë³„ ì˜ˆì¸¡ vs ì‹¤ì œ ê°’ ê²€ì¦ ê·¸ë˜í”„ ìƒì„± - ê°œì„ ëœ ë””ë²„ê¹… ë²„ì „"""
        print("ğŸ” Step-by-step ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì‹œì‘...")
        
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            import os
            
            model.eval()
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘
            print("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            all_states = []
            all_actions = []
            all_targets = []
            
            # ë°ì´í„° ìˆ˜ì§‘ (ë” ë§ì€ ë°°ì¹˜)
            batch_count = 0
            for batch_states, batch_actions, batch_targets in test_loader:
                all_states.append(batch_states)
                all_actions.append(batch_actions) 
                all_targets.append(batch_targets)
                batch_count += 1
                
                if batch_count >= 5:  # ë” ë§ì€ ë°°ì¹˜ ìˆ˜ì§‘
                    break
            
            print(f"âœ… {batch_count}ê°œ ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ")
            
            if len(all_states) < 1:
                print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return
            
            # ë°ì´í„° ê²°í•©
            states_tensor = torch.cat(all_states, dim=0)
            actions_tensor = torch.cat(all_actions, dim=0) 
            targets_tensor = torch.cat(all_targets, dim=0)
            
            print(f"ğŸ“Š ê²°í•©ëœ ë°ì´í„° í¬ê¸°:")
            print(f"   States: {states_tensor.shape}")
            print(f"   Actions: {actions_tensor.shape}")
            print(f"   Targets: {targets_tensor.shape}")
            
            # ì—°ì† ì˜ˆì¸¡ ìˆ˜í–‰
            print("ğŸ”® ì—°ì† ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
            predictions = []
            actual_values = []
            
            # ë” ì•ˆì „í•œ ì‹œì‘ì  ì„¤ì •
            start_idx = min(10, len(states_tensor) - 1)  # ì•ˆì „í•œ ì‹œì‘ì 
            current_state_seq = states_tensor[start_idx:start_idx+1]
            current_action_seq = actions_tensor[start_idx:start_idx+1]
            
            max_steps = min(num_steps, len(targets_tensor) - start_idx - 1)
            print(f"   ì‹œì‘ ì¸ë±ìŠ¤: {start_idx}")
            print(f"   ìµœëŒ€ ì˜ˆì¸¡ ìŠ¤í…: {max_steps}")
            
            with torch.no_grad():
                for step in range(max_steps):
                    try:
                        # ë‹¤ìŒ ìƒíƒœ ì˜ˆì¸¡
                        next_state_pred = model(current_state_seq, current_action_seq)
                        predictions.append(next_state_pred[0].numpy())
                        
                        # ì‹¤ì œ ë‹¤ìŒ ìƒíƒœ
                        actual_idx = start_idx + step + 1
                        if actual_idx < len(targets_tensor):
                            actual_values.append(targets_tensor[actual_idx].numpy())
                        
                        # ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•œ ìƒíƒœ ì—…ë°ì´íŠ¸
                        next_idx = start_idx + step + 1
                        if next_idx < len(states_tensor):
                            current_state_seq = states_tensor[next_idx:next_idx+1]
                            current_action_seq = actions_tensor[next_idx:next_idx+1]
                        
                    except Exception as pred_error:
                        print(f"âš ï¸ ìŠ¤í… {step}ì—ì„œ ì˜ˆì¸¡ ì˜¤ë¥˜: {pred_error}")
                        break
            
            print(f"âœ… {len(predictions)}ê°œ ìŠ¤í… ì˜ˆì¸¡ ì™„ë£Œ")
            
            if len(predictions) == 0:
                print("âŒ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë°°ì—´ ë³€í™˜
            predictions = np.array(predictions)
            actual_values = np.array(actual_values[:len(predictions)])  # ê¸¸ì´ ë§ì¶”ê¸°
            
            print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í¬ê¸°:")
            print(f"   Predictions: {predictions.shape}")
            print(f"   Actual: {actual_values.shape}")
            
            # ì—­ì •ê·œí™” ì‹œë„
            try:
                if hasattr(processor, 'state_scaler') and hasattr(processor.state_scaler, 'inverse_transform'):
                    pred_rescaled = processor.state_scaler.inverse_transform(predictions)
                    actual_rescaled = processor.state_scaler.inverse_transform(actual_values)
                    print("âœ… ì—­ì •ê·œí™” ì™„ë£Œ")
                else:
                    pred_rescaled = predictions.copy()
                    actual_rescaled = actual_values.copy()
                    print("âš ï¸ ì •ê·œí™”ëœ ê°’ ì‚¬ìš©")
            except Exception as e:
                print(f"âš ï¸ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
                pred_rescaled = predictions.copy()
                actual_rescaled = actual_values.copy()
            
            # ìƒíƒœ ì´ë¦„ ì •ì˜ - Power ì œê±°
            state_dim = predictions.shape[1]
            if state_dim == 5:
                state_names = ['Tpip_in_next', 'Tpip_out_next', 'Tbdy_next', 'Tid_next', 'Tod_next']
            elif state_dim == 9:
                state_names = ['Tpip_in1_next', 'Tpip_in2_next', 'Tpip_out1_next', 'Tpip_out2_next', 
                              'Tbdy1_next', 'Tbdy2_next', 'Tid1_next', 'Tid2_next', 'Tod_next']
            else:
                state_names = [f'State_{i+1}_next' for i in range(state_dim)]
            
            print(f"ğŸ“Š ìƒíƒœ ì´ë¦„: {state_names[:min(5, len(state_names))]}...")
            
            # ê·¸ë˜í”„ ìƒì„±
            print("ğŸ¨ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
            n_features = min(10, state_dim)
            
            if n_features <= 5:
                rows, cols = 2, 3
            elif n_features <= 8:
                rows, cols = 2, 4
            else:
                rows, cols = 2, 5
            
            fig, axes = plt.subplots(rows, cols, figsize=(20, 8))
            fig.suptitle(f'Step-by-Step Prediction vs Actual Validation (Auto IDë³„ 5ë¶„ ê°„ê²©)\n({len(predictions)} steps prediction)', 
                        fontsize=16, fontweight='bold')
            
            # axes ì²˜ë¦¬
            if rows == 1:
                axes = axes.reshape(1, -1)
            axes_flat = axes.flatten()
            
            for i in range(n_features):
                ax = axes_flat[i]
                
                # ìŠ¤í…ë³„ ë°ì´í„°
                steps = range(len(pred_rescaled))
                true_values = actual_rescaled[:, i]
                pred_values = pred_rescaled[:, i]
                
                # Step plot
                ax.step(steps, true_values, where='post', label='True', color='blue', 
                       linewidth=2, marker='o', markersize=4)
                ax.step(steps, pred_values, where='post', label='Predicted', color='orange', 
                       linewidth=2, marker='s', markersize=4)
                
                ax.set_title(f'{state_names[i]}', fontweight='bold', fontsize=12)
                ax.set_xlabel('Prediction Step')
                ax.set_ylabel('Value')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                # MAE ê³„ì‚° ë° í‘œì‹œ
                mae = np.mean(np.abs(pred_values - true_values))
                ax.text(0.05, 0.95, f'MAE: {mae:.3f}', transform=ax.transAxes, 
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
                       fontsize=10)
            
            # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
            for i in range(n_features, len(axes_flat)):
                axes_flat[i].set_visible(False)
            
            plt.tight_layout()
            
            # ì €ì¥ ì‹œë„ (ì—¬ëŸ¬ ê²½ë¡œ)
            print("ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...")
            save_paths = [
                'step_by_step_validation.png',
                os.path.join(os.getcwd(), 'step_by_step_validation.png'),
                os.path.join(os.path.expanduser('~'), 'step_by_step_validation.png'),
                os.path.join(os.path.expanduser('~'), 'Desktop', 'step_by_step_validation.png')
            ]
            
            saved = False
            for i, save_path in enumerate(save_paths):
                try:
                    # ë””ë ‰í† ë¦¬ í™•ì¸
                    save_dir = os.path.dirname(save_path)
                    if save_dir and not os.path.exists(save_dir):
                        os.makedirs(save_dir, exist_ok=True)
                    
                    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
                    
                    # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
                    if os.path.exists(save_path) and os.path.getsize(save_path) > 1000:
                        print(f"âœ… Step-by-step ê²€ì¦ ê·¸ë˜í”„ ì €ì¥: '{save_path}'")
                        print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(save_path)} bytes")
                        saved = True
                        break
                    else:
                        print(f"âš ï¸ ì €ì¥ ì‹¤íŒ¨ ë˜ëŠ” íŒŒì¼ í¬ê¸° ë¬¸ì œ: {save_path}")
                        
                except Exception as save_error:
                    print(f"âš ï¸ ì €ì¥ ì‹œë„ {i+1} ì‹¤íŒ¨: {save_error}")
                    continue
            
            plt.close()
            
            if not saved:
                print("âŒ ëª¨ë“  ê²½ë¡œì—ì„œ ì €ì¥ ì‹¤íŒ¨")
                print("ğŸ“Š ë°ì´í„° ìš”ì•½:")
                overall_mae = np.mean(np.abs(pred_rescaled - actual_rescaled))
                print(f"   ì „ì²´ MAE: {overall_mae:.3f}")
                print(f"   ì˜ˆì¸¡ ìŠ¤í…: {len(predictions)}")
                print(f"   ìƒíƒœ ì°¨ì›: {state_dim}")
            else:
                # ì„±ëŠ¥ ìš”ì•½
                overall_mae = np.mean(np.abs(pred_rescaled - actual_rescaled))
                print(f"ğŸ“Š Step-by-step ê²€ì¦ ì„±ëŠ¥:")
                print(f"   ì „ì²´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨: {overall_mae:.3f}")
                print(f"   ì˜ˆì¸¡ ìŠ¤í… ìˆ˜: {len(predictions)}")
                print(f"   ìƒíƒœ ì°¨ì›: {state_dim}")
                
        except Exception as e:
            print(f"âŒ Step-by-step ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    def create_single_step_validation(self, model, test_loader, processor, num_samples=5):
        """ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ vs ì‹¤ì œ ê°’ ë¹„êµ (Bar Chart ìŠ¤íƒ€ì¼) - ê°œì„ ëœ ë²„ì „"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            model.eval()
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ
            sample_states, sample_actions, sample_targets = next(iter(test_loader))
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            with torch.no_grad():
                predictions = model(sample_states[:num_samples], sample_actions[:num_samples])
            
            predictions_np = predictions.numpy()
            targets_np = sample_targets[:num_samples].numpy()
            
            # ì—­ì •ê·œí™” ì‹œë„
            try:
                if hasattr(processor, 'state_scaler'):
                    pred_rescaled = processor.state_scaler.inverse_transform(predictions_np)  
                    actual_rescaled = processor.state_scaler.inverse_transform(targets_np)
                else:
                    pred_rescaled = predictions_np
                    actual_rescaled = targets_np
            except:
                pred_rescaled = predictions_np
                actual_rescaled = targets_np
            
            # ìƒíƒœ ì´ë¦„ ì •ì˜ - Power ì œê±°
            state_dim = predictions_np.shape[1]
            if state_dim == 5:
                state_names = ['Tpip_in', 'Tpip_out', 'Tbdy', 'Tid', 'Tod']
            elif state_dim == 9:
                state_names = ['Tpip_in1', 'Tpip_in2', 'Tpip_out1', 'Tpip_out2', 
                              'Tbdy1', 'Tbdy2', 'Tid1', 'Tid2', 'Tod']
            else:
                state_names = [f'State_{i+1}' for i in range(state_dim)]
            
            # ê·¸ë˜í”„ ìƒì„± (3x4 ê·¸ë¦¬ë“œ)
            n_features = min(12, state_dim)
            rows = 3
            cols = 4
            
            fig, axes = plt.subplots(rows, cols, figsize=(16, 12))
            fig.suptitle('Single-Step Prediction vs Actual Comparison (Auto IDë³„ 5ë¶„ ê°„ê²©)\n(ê° ìƒ˜í”Œì€ ì„œë¡œ ë‹¤ë¥¸ ì‹œì ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°)', 
                        fontsize=16, fontweight='bold')
            
            axes_flat = axes.flatten()
            
            for i in range(n_features):
                ax = axes_flat[i]
                
                # ê° ìƒ˜í”Œì— ëŒ€í•´ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ë¹„êµ
                pred_values = pred_rescaled[:, i]
                actual_values = actual_rescaled[:, i]
                
                # ë°” ì°¨íŠ¸
                x = np.arange(num_samples)
                width = 0.35
                
                bars1 = ax.bar(x - width/2, actual_values, width, label='Actual', 
                              alpha=0.8, color='skyblue')
                bars2 = ax.bar(x + width/2, pred_values, width, label='Predicted', 
                              alpha=0.8, color='lightcoral')
                
                # ì˜¤ì°¨ í‘œì‹œ
                errors = np.abs(pred_values - actual_values)
                for j, (actual, pred, error) in enumerate(zip(actual_values, pred_values, errors)):
                    ax.text(j, max(actual, pred) + abs(max(actual, pred)) * 0.05, 
                           f'{error:.2f}', ha='center', va='bottom', fontsize=8)
                
                ax.set_title(f'{state_names[i]}', fontweight='bold')
                ax.set_xlabel('Test Sample Index\n(ê° ìƒ˜í”Œ = ë‹¤ë¥¸ ì‹œì ì˜ ë°ì´í„°)')
                ax.set_ylabel('State Value')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                # xì¶• ë¼ë²¨ì„ ë” ëª…í™•í•˜ê²Œ
                ax.set_xticks(x)
                ax.set_xticklabels([f'Sample\n{i}' for i in range(num_samples)])
            
            # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
            for i in range(n_features, len(axes_flat)):
                axes_flat[i].set_visible(False)
            
            plt.tight_layout()
            
            # ì €ì¥
            save_paths = [
                'single_step_validation.png',
                os.path.join(os.path.expanduser('~'), 'single_step_validation.png'),
                os.path.join(os.path.expanduser('~'), 'Desktop', 'single_step_validation.png')
            ]
            
            for save_path in save_paths:
                try:
                    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
                    if os.path.exists(save_path):
                        print(f"âœ… ë‹¨ì¼ ìŠ¤í… ê²€ì¦ ê·¸ë˜í”„ ì €ì¥: '{save_path}'")
                        print(f"   ğŸ“Š Xì¶•: í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì¸ë±ìŠ¤ (0~{num_samples-1})")
                        print(f"   ğŸ“Š Yì¶•: ê° ìƒíƒœì˜ ê°’ (ì˜ˆì¸¡ vs ì‹¤ì œ)")
                        print(f"   ğŸ“Š ë§‰ëŒ€ ìœ„ ìˆ«ì: ì ˆëŒ€ ì˜¤ì°¨")
                        break
                except:
                    continue
            
            plt.close()
            
            # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
            print(f"\nğŸ“ˆ ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ ì„±ëŠ¥:")
            overall_mae = np.mean(np.abs(pred_rescaled - actual_rescaled))
            print(f"   ì „ì²´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨: {overall_mae:.3f}")
            print(f"   í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {num_samples}")
            print(f"   ìƒíƒœ ì°¨ì›: {state_dim}")
            
        except Exception as e:
            print(f"âŒ ë‹¨ì¼ ìŠ¤í… ê²€ì¦ ê·¸ë˜í”„ ì˜¤ë¥˜: {e}")
    
    def save_losses_to_csv(self):
        """ì†ì‹¤ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥"""
        try:
            import pandas as pd
            import os
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df = pd.DataFrame({
                'epoch': range(1, len(self.train_losses) + 1),
                'train_loss': self.train_losses,
                'val_loss': self.val_losses,
                'gap': [val - train for train, val in zip(self.train_losses, self.val_losses)]
            })
            
            # ì €ì¥ ê²½ë¡œë“¤
            save_paths = [
                'training_losses.csv',
                os.path.join(os.path.expanduser('~'), 'training_losses.csv'),
                os.path.join(os.path.expanduser('~'), 'Desktop', 'training_losses.csv')
            ]
            
            for save_path in save_paths:
                try:
                    df.to_csv(save_path, index=False)
                    if os.path.exists(save_path):
                        print(f"âœ… ì†ì‹¤ ë°ì´í„° CSV ì €ì¥: '{save_path}'")
                        return save_path
                except:
                    continue
                    
            print("âš ï¸ CSV ì €ì¥ ì‹¤íŒ¨")
            return None
        except Exception as e:
            print(f"âŒ csv ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def create_simple_step_validation(self, model, test_loader, processor, num_samples=3):
        """ê°„ë‹¨í•œ step-by-step ê²€ì¦ ê·¸ë˜í”„ (ëŒ€ì•ˆ ë°©ë²•)"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            import os
            
            print("ğŸ¨ ê°„ë‹¨í•œ step-by-step ê²€ì¦ ê·¸ë˜í”„ ìƒì„±...")
            
            model.eval()
            
            # ê°„ë‹¨í•œ ë°©ë²•: ì—¬ëŸ¬ ê°œë³„ ì˜ˆì¸¡ì„ ì—°ê²°
            sample_states, sample_actions, sample_targets = next(iter(test_loader))
            
            # ì²« ëª‡ ê°œ ìƒ˜í”Œë¡œ ì—°ì† ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜
            predictions_list = []
            actuals_list = []
            
            with torch.no_grad():
                for i in range(min(num_samples, len(sample_states))):
                    # ê° ìƒ˜í”Œì— ëŒ€í•´ ì˜ˆì¸¡
                    pred = model(sample_states[i:i+1], sample_actions[i:i+1])
                    predictions_list.append(pred[0].numpy())
                    actuals_list.append(sample_targets[i].numpy())
            
            if len(predictions_list) == 0:
                print("âŒ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            predictions = np.array(predictions_list)
            actuals = np.array(actuals_list)
            
            # ì—­ì •ê·œí™”
            try:
                if hasattr(processor, 'state_scaler'):
                    pred_rescaled = processor.state_scaler.inverse_transform(predictions)
                    actual_rescaled = processor.state_scaler.inverse_transform(actuals)
                else:
                    pred_rescaled = predictions
                    actual_rescaled = actuals
            except Exception as e:
                print(f"âš ï¸ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
                pred_rescaled = predictions
                actual_rescaled = actuals
            
            # ìƒíƒœ ì´ë¦„ - Power ì œê±°
            state_dim = predictions.shape[1]
            if state_dim == 5:
                state_names = ['Tpip_in', 'Tpip_out', 'Tbdy', 'Tid', 'Tod']
            elif state_dim == 9:
                state_names = ['Tpip_in1', 'Tpip_in2', 'Tpip_out1', 'Tpip_out2', 
                              'Tbdy1', 'Tbdy2', 'Tid1', 'Tid2', 'Tod']
            else:
                state_names = [f'State_{i+1}' for i in range(state_dim)]
            
            # ê·¸ë˜í”„ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
            n_features = min(6, state_dim)  # 6ê°œë§Œ í‘œì‹œ
            fig, axes = plt.subplots(2, 3, figsize=(15, 8))
            fig.suptitle(f'Simple Step-by-Step Validation (Auto IDë³„ 5ë¶„ ê°„ê²©, {num_samples} steps)', 
                        fontsize=14, fontweight='bold')
            
            axes_flat = axes.flatten()
            
            for i in range(n_features):
                ax = axes_flat[i]
                
                steps = range(len(pred_rescaled))
                true_vals = actual_rescaled[:, i]
                pred_vals = pred_rescaled[:, i]
                
                # ë‹¨ìˆœí•œ ë¼ì¸ í”Œë¡¯
                ax.plot(steps, true_vals, 'b-o', label='True', linewidth=2, markersize=6)
                ax.plot(steps, pred_vals, 'r-s', label='Predicted', linewidth=2, markersize=6)
                
                ax.set_title(f'{state_names[i]}', fontweight='bold')
                ax.set_xlabel('Step')
                ax.set_ylabel('Value')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                # MAE
                mae = np.mean(np.abs(pred_vals - true_vals))
                ax.text(0.05, 0.95, f'MAE: {mae:.3f}', transform=ax.transAxes,
                       bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
            
            plt.tight_layout()
            
            # ì €ì¥
            save_path = 'simple_step_validation.png'
            try:
                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
                if os.path.exists(save_path):
                    print(f"âœ… ê°„ë‹¨í•œ step-by-step ê·¸ë˜í”„ ì €ì¥: '{save_path}'")
                    return save_path
            except Exception as e:
                print(f"âŒ ê°„ë‹¨í•œ ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            plt.close()
            
        except Exception as e:
            print(f"âŒ ê°„ë‹¨í•œ step-by-step ê·¸ë˜í”„ ì˜¤ë¥˜: {e}")
            return None

class ImprovedSSMTrainer(SSMTrainer):
    """ê°œì„ ëœ SSM í›ˆë ¨ í´ë˜ìŠ¤ - Lag-1 ë¬¸ì œ í•´ê²°"""
    
    def __init__(self, model: SimpleSSMWorldModel, learning_rate: float = 0.001):
        super().__init__(model, learning_rate)
        # ë°©í–¥ì„± ì •í™•ë„ë¥¼ ìœ„í•œ ì¶”ê°€ ë©”íŠ¸ë¦­
        self.directional_losses = []
        
    def calculate_directional_loss(self, predictions: torch.Tensor, targets: torch.Tensor, 
                                 prev_states: torch.Tensor) -> torch.Tensor:
        """ë°©í–¥ì„± ì†ì‹¤ ê³„ì‚° - ë³€í™” ë°©í–¥ì„ ë§ì¶”ëŠ”ì§€ í™•ì¸"""
        # ì´ì „ ìƒíƒœ ëŒ€ë¹„ ë³€í™”ëŸ‰ ê³„ì‚°
        pred_changes = predictions - prev_states  # ì˜ˆì¸¡ëœ ë³€í™”ëŸ‰
        true_changes = targets - prev_states      # ì‹¤ì œ ë³€í™”ëŸ‰
        
        # ë°©í–¥ì„± ì¼ì¹˜ë„ ê³„ì‚° (ë¶€í˜¸ê°€ ê°™ìœ¼ë©´ 1, ë‹¤ë¥´ë©´ -1)
        directional_accuracy = torch.sign(pred_changes) * torch.sign(true_changes)
        
        # ë°©í–¥ì„± ì†ì‹¤ (ë°©í–¥ì´ í‹€ë¦¬ë©´ í˜ë„í‹°)
        directional_loss = torch.mean(torch.relu(-directional_accuracy + 0.1))
        
        return directional_loss
    
    def train_epoch(self, train_loader: DataLoader) -> float:
        """í•œ ì—í¬í¬ í›ˆë ¨ - ê°œì„ ëœ ì†ì‹¤ í•¨ìˆ˜"""
        self.model.train()
        total_loss = 0.0
        total_directional_loss = 0.0
        
        for states, actions, targets in train_loader:
            self.optimizer.zero_grad()
            predictions = self.model(states, actions)
            
            # ê¸°ë³¸ MSE ì†ì‹¤
            mse_loss = self.criterion(predictions, targets)
            
            # ë°©í–¥ì„± ì†ì‹¤ (ì´ì „ ìƒíƒœì™€ ë¹„êµ)
            prev_states = states[:, -1]  # ë§ˆì§€ë§‰ ìƒíƒœë¥¼ ì´ì „ ìƒíƒœë¡œ ì‚¬ìš©
            directional_loss = self.calculate_directional_loss(predictions, targets, prev_states)
            
            # ê²°í•©ëœ ì†ì‹¤ (MSE + ë°©í–¥ì„±)
            combined_loss = mse_loss + 0.2 * directional_loss
            
            combined_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.1)
            self.optimizer.step()
            
            total_loss += mse_loss.item()
            total_directional_loss += directional_loss.item()
            
        avg_loss = total_loss / len(train_loader)
        avg_directional_loss = total_directional_loss / len(train_loader)
        self.directional_losses.append(avg_directional_loss)
        
        return avg_loss
    
    def create_lag1_comparison_plot(self, model, test_loader, processor):
        """Lag-1 ì˜ˆì¸¡ê³¼ ì‹¤ì œ ì˜ˆì¸¡ ë¹„êµ ê·¸ë˜í”„"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            import os
            
            model.eval()
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            sample_states, sample_actions, sample_targets = next(iter(test_loader))
            
            with torch.no_grad():
                predictions = model(sample_states[:10], sample_actions[:10])
                
            predictions_np = predictions.numpy()
            targets_np = sample_targets[:10].numpy()
            prev_states_np = sample_states[:10, -1].numpy()  # ì´ì „ ìƒíƒœ
            
            # ì—­ì •ê·œí™”
            try:
                if hasattr(processor, 'state_scaler'):
                    pred_rescaled = processor.state_scaler.inverse_transform(predictions_np)
                    actual_rescaled = processor.state_scaler.inverse_transform(targets_np)
                    prev_rescaled = processor.state_scaler.inverse_transform(prev_states_np)
                else:
                    pred_rescaled = predictions_np
                    actual_rescaled = targets_np
                    prev_rescaled = prev_states_np
            except:
                pred_rescaled = predictions_np
                actual_rescaled = targets_np
                prev_rescaled = prev_states_np
            
            # Lag-1 ì˜ˆì¸¡ (ì´ì „ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            lag1_predictions = prev_rescaled.copy()
            
            # ì²« ë²ˆì§¸ ìƒíƒœ (ì˜¨ë„) ë¹„êµ
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('Lag-1 Problem Analysis: Real Prediction vs Lag-1 Copy', 
                        fontsize=16, fontweight='bold')
            
            # ì‹¤ë‚´ì˜¨ë„ (Tid) ë¹„êµ
            temp_idx = 3 if pred_rescaled.shape[1] >= 4 else 0
            
            axes[0, 0].plot(range(10), actual_rescaled[:, temp_idx], 'g-o', 
                           label='Actual', linewidth=2, markersize=6)
            axes[0, 0].plot(range(10), pred_rescaled[:, temp_idx], 'b-s', 
                           label='Model Prediction', linewidth=2, markersize=6)
            axes[0, 0].plot(range(10), lag1_predictions[:, temp_idx], 'r--^', 
                           label='Lag-1 (Previous Value)', linewidth=2, markersize=6)
            axes[0, 0].set_title('Temperature Prediction Comparison')
            axes[0, 0].set_xlabel('Sample Index')
            axes[0, 0].set_ylabel('Temperature (Â°C)')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # ë³€í™”ëŸ‰ ë¹„êµ
            actual_changes = actual_rescaled[:, temp_idx] - prev_rescaled[:, temp_idx]
            pred_changes = pred_rescaled[:, temp_idx] - prev_rescaled[:, temp_idx]
            lag1_changes = np.zeros_like(actual_changes)  # Lag-1ì€ ë³€í™”ëŸ‰ì´ 0
            
            axes[0, 1].bar(np.arange(10) - 0.2, actual_changes, 0.2, 
                          label='Actual Change', alpha=0.7, color='green')
            axes[0, 1].bar(np.arange(10), pred_changes, 0.2, 
                          label='Predicted Change', alpha=0.7, color='blue')
            axes[0, 1].bar(np.arange(10) + 0.2, lag1_changes, 0.2, 
                          label='Lag-1 Change (0)', alpha=0.7, color='red')
            axes[0, 1].set_title('Change Amount Comparison')
            axes[0, 1].set_xlabel('Sample Index')
            axes[0, 1].set_ylabel('Temperature Change (Â°C)')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
            
            # ì˜¤ì°¨ ë¹„êµ
            model_errors = np.abs(pred_rescaled[:, temp_idx] - actual_rescaled[:, temp_idx])
            lag1_errors = np.abs(lag1_predictions[:, temp_idx] - actual_rescaled[:, temp_idx])
            
            axes[1, 0].bar(np.arange(10) - 0.2, model_errors, 0.4, 
                          label=f'Model MAE: {np.mean(model_errors):.3f}', 
                          alpha=0.7, color='blue')
            axes[1, 0].bar(np.arange(10) + 0.2, lag1_errors, 0.4, 
                          label=f'Lag-1 MAE: {np.mean(lag1_errors):.3f}', 
                          alpha=0.7, color='red')
            axes[1, 0].set_title('Prediction Error Comparison')
            axes[1, 0].set_xlabel('Sample Index')
            axes[1, 0].set_ylabel('Absolute Error')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
            
            # ë°©í–¥ì„± ì •í™•ë„
            model_directions = np.sign(pred_changes)
            actual_directions = np.sign(actual_changes)
            directional_accuracy = (model_directions == actual_directions).astype(int)
            
            axes[1, 1].bar(range(10), directional_accuracy, alpha=0.7, color='purple')
            axes[1, 1].set_title(f'Directional Accuracy: {np.mean(directional_accuracy)*100:.1f}%')
            axes[1, 1].set_xlabel('Sample Index')
            axes[1, 1].set_ylabel('Direction Match (1=Correct, 0=Wrong)')
            axes[1, 1].set_ylim([0, 1.2])
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ì €ì¥
            save_path = 'lag1_problem_analysis.png'
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
            
            if os.path.exists(save_path):
                print(f"âœ… Lag-1 ë¬¸ì œ ë¶„ì„ ê·¸ë˜í”„ ì €ì¥: '{save_path}'")
                print(f"   ğŸ“Š ëª¨ë¸ MAE: {np.mean(model_errors):.3f}")
                print(f"   ğŸ“Š Lag-1 MAE: {np.mean(lag1_errors):.3f}")  
                print(f"   ğŸ“Š ë°©í–¥ì„± ì •í™•ë„: {np.mean(directional_accuracy)*100:.1f}%")
            
            plt.close()
            
        except Exception as e:
            print(f"âŒ Lag-1 ë¶„ì„ ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
    """SSM World Model í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, model: SimpleSSMWorldModel, learning_rate: float = 0.001):
        self.model = model
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', patience=3, factor=0.7)
        self.criterion = nn.MSELoss()
        self.train_losses = []
        self.val_losses = []
        
    def train_epoch(self, train_loader: DataLoader) -> float:
        """í•œ ì—í¬í¬ í›ˆë ¨"""
        self.model.train()
        total_loss = 0.0
        
        for states, actions, targets in train_loader:
            self.optimizer.zero_grad()
            predictions = self.model(states, actions)
            loss = self.criterion(predictions, targets)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=0.1)
            self.optimizer.step()
            total_loss += loss.item()
            
        return total_loss / len(train_loader)
    
    def validate(self, val_loader: DataLoader) -> float:
        """ê²€ì¦"""
        self.model.eval()
        total_loss = 0.0
        
        with torch.no_grad():
            for states, actions, targets in val_loader:
                predictions = self.model(states, actions)
                loss = self.criterion(predictions, targets)
                total_loss += loss.item()
                
        return total_loss / len(val_loader)
    
    def train(self, train_loader: DataLoader, val_loader: DataLoader, 
              epochs: int = 50, patience: int = 10) -> Dict:
        """ì „ì²´ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤"""
        best_val_loss = float('inf')
        patience_counter = 0
        min_improvement = 1e-4
        
        for epoch in range(epochs):
            train_loss = self.train_epoch(train_loader)
            val_loss = self.validate(val_loader)
            self.scheduler.step(val_loss)
            
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            
            current_lr = self.optimizer.param_groups[0]['lr']
            improvement = best_val_loss - val_loss
            
            print(f"Epoch {epoch+1:2d}/{epochs} - Train: {train_loss:.4f}, Val: {val_loss:.4f}, "
                  f"LR: {current_lr:.1e}, Gap: {val_loss-train_loss:.4f}")
            
            if improvement > min_improvement:
                best_val_loss = val_loss
                patience_counter = 0
                torch.save(self.model.state_dict(), 'best_simple_ssm_model.pth')
                print(f"    âœ“ New best! Improvement: {improvement:.4f}")
            else:
                patience_counter += 1
                print(f"    No improvement ({patience_counter}/{patience})")
                
            if patience_counter >= patience:
                print(f"Early stopping at epoch {epoch+1}")
                break
                
            if val_loss - train_loss > 0.5:
                print(f"Overfitting detected! Gap: {val_loss - train_loss:.4f}")
                break
                
        return {
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'best_val_loss': best_val_loss
        }
    
    def plot_losses(self):
        """ì†ì‹¤ ê·¸ë˜í”„ ì‹œê°í™”"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            save_path = 'training_progress.png'
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
            
            # ì²« ë²ˆì§¸ ì„œë¸Œí”Œë¡¯: ì†ì‹¤ ê³¡ì„ 
            ax1.plot(self.train_losses, label='Training Loss', color='blue', linewidth=2, marker='o', markersize=3)
            ax1.plot(self.val_losses, label='Validation Loss', color='red', linewidth=2, marker='s', markersize=3)
            ax1.set_xlabel('Epoch')
            ax1.set_ylabel('Loss')
            ax1.set_title('Training Progress (Auto IDë³„ 5ë¶„ ê°„ê²© ìƒ˜í”Œë§)', fontsize=14, fontweight='bold')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            ax1.set_yscale('log')
            
            # ë‘ ë²ˆì§¸ ì„œë¸Œí”Œë¡¯: ê³¼ì í•© ëª¨ë‹ˆí„°
            gaps = [val - train for train, val in zip(self.train_losses, self.val_losses)]
            ax2.plot(gaps, label='Val - Train Gap', color='orange', linewidth=2, marker='^', markersize=3)
            ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
            ax2.set_xlabel('Epoch')
            ax2.set_ylabel('Loss Gap')
            ax2.set_title('Overfitting Monitor (Gap should be close to 0)', fontsize=14, fontweight='bold')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
            
            if os.path.exists(save_path) and os.path.getsize(save_path) > 0:
                print(f"âœ… Training progress saved as '{save_path}'")
                print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(save_path)} bytes")
            else:
                print("âŒ ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨")
                
            plt.close()
            
        except Exception as e:
            print(f"âŒ ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
            print("ì†ì‹¤ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤:")
            print(f"í›ˆë ¨ ì†ì‹¤: {self.train_losses}")
            print(f"ê²€ì¦ ì†ì‹¤: {self.val_losses}")
    
    def create_validation_plots(self, model, test_loader, processor, num_steps=10):
        """ìŠ¤í…ë³„ ì˜ˆì¸¡ vs ì‹¤ì œ ê°’ ê²€ì¦ ê·¸ë˜í”„ ìƒì„± - ê°œì„ ëœ ë””ë²„ê¹… ë²„ì „"""
        print("ğŸ” Step-by-step ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì‹œì‘...")
        
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            import os
            
            model.eval()
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘
            print("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            all_states = []
            all_actions = []
            all_targets = []
            
            # ë°ì´í„° ìˆ˜ì§‘ (ë” ë§ì€ ë°°ì¹˜)
            batch_count = 0
            for batch_states, batch_actions, batch_targets in test_loader:
                all_states.append(batch_states)
                all_actions.append(batch_actions) 
                all_targets.append(batch_targets)
                batch_count += 1
                
                if batch_count >= 5:  # ë” ë§ì€ ë°°ì¹˜ ìˆ˜ì§‘
                    break
            
            print(f"âœ… {batch_count}ê°œ ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ")
            
            if len(all_states) < 1:
                print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                return
            
            # ë°ì´í„° ê²°í•©
            states_tensor = torch.cat(all_states, dim=0)
            actions_tensor = torch.cat(all_actions, dim=0) 
            targets_tensor = torch.cat(all_targets, dim=0)
            
            print(f"ğŸ“Š ê²°í•©ëœ ë°ì´í„° í¬ê¸°:")
            print(f"   States: {states_tensor.shape}")
            print(f"   Actions: {actions_tensor.shape}")
            print(f"   Targets: {targets_tensor.shape}")
            
            # ì—°ì† ì˜ˆì¸¡ ìˆ˜í–‰
            print("ğŸ”® ì—°ì† ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
            predictions = []
            actual_values = []
            
            # ë” ì•ˆì „í•œ ì‹œì‘ì  ì„¤ì •
            start_idx = min(10, len(states_tensor) - 1)  # ì•ˆì „í•œ ì‹œì‘ì 
            current_state_seq = states_tensor[start_idx:start_idx+1]
            current_action_seq = actions_tensor[start_idx:start_idx+1]
            
            max_steps = min(num_steps, len(targets_tensor) - start_idx - 1)
            print(f"   ì‹œì‘ ì¸ë±ìŠ¤: {start_idx}")
            print(f"   ìµœëŒ€ ì˜ˆì¸¡ ìŠ¤í…: {max_steps}")
            
            with torch.no_grad():
                for step in range(max_steps):
                    try:
                        # ë‹¤ìŒ ìƒíƒœ ì˜ˆì¸¡
                        next_state_pred = model(current_state_seq, current_action_seq)
                        predictions.append(next_state_pred[0].numpy())
                        
                        # ì‹¤ì œ ë‹¤ìŒ ìƒíƒœ
                        actual_idx = start_idx + step + 1
                        if actual_idx < len(targets_tensor):
                            actual_values.append(targets_tensor[actual_idx].numpy())
                        
                        # ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•œ ìƒíƒœ ì—…ë°ì´íŠ¸
                        next_idx = start_idx + step + 1
                        if next_idx < len(states_tensor):
                            current_state_seq = states_tensor[next_idx:next_idx+1]
                            current_action_seq = actions_tensor[next_idx:next_idx+1]
                        
                    except Exception as pred_error:
                        print(f"âš ï¸ ìŠ¤í… {step}ì—ì„œ ì˜ˆì¸¡ ì˜¤ë¥˜: {pred_error}")
                        break
            
            print(f"âœ… {len(predictions)}ê°œ ìŠ¤í… ì˜ˆì¸¡ ì™„ë£Œ")
            
            if len(predictions) == 0:
                print("âŒ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë°°ì—´ ë³€í™˜
            predictions = np.array(predictions)
            actual_values = np.array(actual_values[:len(predictions)])  # ê¸¸ì´ ë§ì¶”ê¸°
            
            print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í¬ê¸°:")
            print(f"   Predictions: {predictions.shape}")
            print(f"   Actual: {actual_values.shape}")
            
            # ì—­ì •ê·œí™” ì‹œë„
            try:
                if hasattr(processor, 'state_scaler') and hasattr(processor.state_scaler, 'inverse_transform'):
                    pred_rescaled = processor.state_scaler.inverse_transform(predictions)
                    actual_rescaled = processor.state_scaler.inverse_transform(actual_values)
                    print("âœ… ì—­ì •ê·œí™” ì™„ë£Œ")
                else:
                    pred_rescaled = predictions.copy()
                    actual_rescaled = actual_values.copy()
                    print("âš ï¸ ì •ê·œí™”ëœ ê°’ ì‚¬ìš©")
            except Exception as e:
                print(f"âš ï¸ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
                pred_rescaled = predictions.copy()
                actual_rescaled = actual_values.copy()
            
            # ìƒíƒœ ì´ë¦„ ì •ì˜ - Power ì œê±°
            state_dim = predictions.shape[1]
            if state_dim == 5:
                state_names = ['Tpip_in_next', 'Tpip_out_next', 'Tbdy_next', 'Tid_next', 'Tod_next']
            elif state_dim == 9:
                state_names = ['Tpip_in1_next', 'Tpip_in2_next', 'Tpip_out1_next', 'Tpip_out2_next', 
                              'Tbdy1_next', 'Tbdy2_next', 'Tid1_next', 'Tid2_next', 'Tod_next']
            else:
                state_names = [f'State_{i+1}_next' for i in range(state_dim)]
            
            print(f"ğŸ“Š ìƒíƒœ ì´ë¦„: {state_names[:min(5, len(state_names))]}...")
            
            # ê·¸ë˜í”„ ìƒì„±
            print("ğŸ¨ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
            n_features = min(10, state_dim)
            
            if n_features <= 5:
                rows, cols = 2, 3
            elif n_features <= 8:
                rows, cols = 2, 4
            else:
                rows, cols = 2, 5
            
            fig, axes = plt.subplots(rows, cols, figsize=(20, 8))
            fig.suptitle(f'Step-by-Step Prediction vs Actual Validation (Auto IDë³„ 5ë¶„ ê°„ê²©)\n({len(predictions)} steps prediction)', 
                        fontsize=16, fontweight='bold')
            
            # axes ì²˜ë¦¬
            if rows == 1:
                axes = axes.reshape(1, -1)
            axes_flat = axes.flatten()
            
            for i in range(n_features):
                ax = axes_flat[i]
                
                # ìŠ¤í…ë³„ ë°ì´í„°
                steps = range(len(pred_rescaled))
                true_values = actual_rescaled[:, i]
                pred_values = pred_rescaled[:, i]
                
                # Step plot
                ax.step(steps, true_values, where='post', label='True', color='blue', 
                       linewidth=2, marker='o', markersize=4)
                ax.step(steps, pred_values, where='post', label='Predicted', color='orange', 
                       linewidth=2, marker='s', markersize=4)
                
                ax.set_title(f'{state_names[i]}', fontweight='bold', fontsize=12)
                ax.set_xlabel('Prediction Step')
                ax.set_ylabel('Value')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                # MAE ê³„ì‚° ë° í‘œì‹œ
                mae = np.mean(np.abs(pred_values - true_values))
                ax.text(0.05, 0.95, f'MAE: {mae:.3f}', transform=ax.transAxes, 
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
                       fontsize=10)
            
            # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
            for i in range(n_features, len(axes_flat)):
                axes_flat[i].set_visible(False)
            
            plt.tight_layout()
            
            # ì €ì¥ ì‹œë„ (ì—¬ëŸ¬ ê²½ë¡œ)
            print("ğŸ’¾ íŒŒì¼ ì €ì¥ ì¤‘...")
            save_paths = [
                'step_by_step_validation.png',
                os.path.join(os.getcwd(), 'step_by_step_validation.png'),
                os.path.join(os.path.expanduser('~'), 'step_by_step_validation.png'),
                os.path.join(os.path.expanduser('~'), 'Desktop', 'step_by_step_validation.png')
            ]
            
            saved = False
            for i, save_path in enumerate(save_paths):
                try:
                    # ë””ë ‰í† ë¦¬ í™•ì¸
                    save_dir = os.path.dirname(save_path)
                    if save_dir and not os.path.exists(save_dir):
                        os.makedirs(save_dir, exist_ok=True)
                    
                    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
                    
                    # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
                    if os.path.exists(save_path) and os.path.getsize(save_path) > 1000:
                        print(f"âœ… Step-by-step ê²€ì¦ ê·¸ë˜í”„ ì €ì¥: '{save_path}'")
                        print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(save_path)} bytes")
                        saved = True
                        break
                    else:
                        print(f"âš ï¸ ì €ì¥ ì‹¤íŒ¨ ë˜ëŠ” íŒŒì¼ í¬ê¸° ë¬¸ì œ: {save_path}")
                        
                except Exception as save_error:
                    print(f"âš ï¸ ì €ì¥ ì‹œë„ {i+1} ì‹¤íŒ¨: {save_error}")
                    continue
            
            plt.close()
            
            if not saved:
                print("âŒ ëª¨ë“  ê²½ë¡œì—ì„œ ì €ì¥ ì‹¤íŒ¨")
                print("ğŸ“Š ë°ì´í„° ìš”ì•½:")
                overall_mae = np.mean(np.abs(pred_rescaled - actual_rescaled))
                print(f"   ì „ì²´ MAE: {overall_mae:.3f}")
                print(f"   ì˜ˆì¸¡ ìŠ¤í…: {len(predictions)}")
                print(f"   ìƒíƒœ ì°¨ì›: {state_dim}")
            else:
                # ì„±ëŠ¥ ìš”ì•½
                overall_mae = np.mean(np.abs(pred_rescaled - actual_rescaled))
                print(f"ğŸ“Š Step-by-step ê²€ì¦ ì„±ëŠ¥:")
                print(f"   ì „ì²´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨: {overall_mae:.3f}")
                print(f"   ì˜ˆì¸¡ ìŠ¤í… ìˆ˜: {len(predictions)}")
                print(f"   ìƒíƒœ ì°¨ì›: {state_dim}")
                
        except Exception as e:
            print(f"âŒ Step-by-step ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
    
    def create_single_step_validation(self, model, test_loader, processor, num_samples=5):
        """ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ vs ì‹¤ì œ ê°’ ë¹„êµ (Bar Chart ìŠ¤íƒ€ì¼) - ê°œì„ ëœ ë²„ì „"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            model.eval()
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì¶”ì¶œ
            sample_states, sample_actions, sample_targets = next(iter(test_loader))
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            with torch.no_grad():
                predictions = model(sample_states[:num_samples], sample_actions[:num_samples])
            
            predictions_np = predictions.numpy()
            targets_np = sample_targets[:num_samples].numpy()
            
            # ì—­ì •ê·œí™” ì‹œë„
            try:
                if hasattr(processor, 'state_scaler'):
                    pred_rescaled = processor.state_scaler.inverse_transform(predictions_np)  
                    actual_rescaled = processor.state_scaler.inverse_transform(targets_np)
                else:
                    pred_rescaled = predictions_np
                    actual_rescaled = targets_np
            except:
                pred_rescaled = predictions_np
                actual_rescaled = targets_np
            
            # ìƒíƒœ ì´ë¦„ ì •ì˜ - Power ì œê±°
            state_dim = predictions_np.shape[1]
            if state_dim == 5:
                state_names = ['Tpip_in', 'Tpip_out', 'Tbdy', 'Tid', 'Tod']
            elif state_dim == 9:
                state_names = ['Tpip_in1', 'Tpip_in2', 'Tpip_out1', 'Tpip_out2', 
                              'Tbdy1', 'Tbdy2', 'Tid1', 'Tid2', 'Tod']
            else:
                state_names = [f'State_{i+1}' for i in range(state_dim)]
            
            # ê·¸ë˜í”„ ìƒì„± (3x4 ê·¸ë¦¬ë“œ)
            n_features = min(12, state_dim)
            rows = 3
            cols = 4
            
            fig, axes = plt.subplots(rows, cols, figsize=(16, 12))
            fig.suptitle('Single-Step Prediction vs Actual Comparison (Auto IDë³„ 5ë¶„ ê°„ê²©)\n(ê° ìƒ˜í”Œì€ ì„œë¡œ ë‹¤ë¥¸ ì‹œì ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°)', 
                        fontsize=16, fontweight='bold')
            
            axes_flat = axes.flatten()
            
            for i in range(n_features):
                ax = axes_flat[i]
                
                # ê° ìƒ˜í”Œì— ëŒ€í•´ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ë¹„êµ
                pred_values = pred_rescaled[:, i]
                actual_values = actual_rescaled[:, i]
                
                # ë°” ì°¨íŠ¸
                x = np.arange(num_samples)
                width = 0.35
                
                bars1 = ax.bar(x - width/2, actual_values, width, label='Actual', 
                              alpha=0.8, color='skyblue')
                bars2 = ax.bar(x + width/2, pred_values, width, label='Predicted', 
                              alpha=0.8, color='lightcoral')
                
                # ì˜¤ì°¨ í‘œì‹œ
                errors = np.abs(pred_values - actual_values)
                for j, (actual, pred, error) in enumerate(zip(actual_values, pred_values, errors)):
                    ax.text(j, max(actual, pred) + abs(max(actual, pred)) * 0.05, 
                           f'{error:.2f}', ha='center', va='bottom', fontsize=8)
                
                ax.set_title(f'{state_names[i]}', fontweight='bold')
                ax.set_xlabel('Test Sample Index\n(ê° ìƒ˜í”Œ = ë‹¤ë¥¸ ì‹œì ì˜ ë°ì´í„°)')
                ax.set_ylabel('State Value')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                # xì¶• ë¼ë²¨ì„ ë” ëª…í™•í•˜ê²Œ
                ax.set_xticks(x)
                ax.set_xticklabels([f'Sample\n{i}' for i in range(num_samples)])
            
            # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
            for i in range(n_features, len(axes_flat)):
                axes_flat[i].set_visible(False)
            
            plt.tight_layout()
            
            # ì €ì¥
            save_paths = [
                'single_step_validation.png',
                os.path.join(os.path.expanduser('~'), 'single_step_validation.png'),
                os.path.join(os.path.expanduser('~'), 'Desktop', 'single_step_validation.png')
            ]
            
            for save_path in save_paths:
                try:
                    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
                    if os.path.exists(save_path):
                        print(f"âœ… ë‹¨ì¼ ìŠ¤í… ê²€ì¦ ê·¸ë˜í”„ ì €ì¥: '{save_path}'")
                        print(f"   ğŸ“Š Xì¶•: í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì¸ë±ìŠ¤ (0~{num_samples-1})")
                        print(f"   ğŸ“Š Yì¶•: ê° ìƒíƒœì˜ ê°’ (ì˜ˆì¸¡ vs ì‹¤ì œ)")
                        print(f"   ğŸ“Š ë§‰ëŒ€ ìœ„ ìˆ«ì: ì ˆëŒ€ ì˜¤ì°¨")
                        break
                except:
                    continue
            
            plt.close()
            
            # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
            print(f"\nğŸ“ˆ ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ ì„±ëŠ¥:")
            overall_mae = np.mean(np.abs(pred_rescaled - actual_rescaled))
            print(f"   ì „ì²´ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨: {overall_mae:.3f}")
            print(f"   í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {num_samples}")
            print(f"   ìƒíƒœ ì°¨ì›: {state_dim}")
            
        except Exception as e:
            print(f"âŒ ë‹¨ì¼ ìŠ¤í… ê²€ì¦ ê·¸ë˜í”„ ì˜¤ë¥˜: {e}")
    
    def save_losses_to_csv(self):
        """ì†ì‹¤ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥"""
        try:
            import pandas as pd
            import os
            
            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df = pd.DataFrame({
                'epoch': range(1, len(self.train_losses) + 1),
                'train_loss': self.train_losses,
                'val_loss': self.val_losses,
                'gap': [val - train for train, val in zip(self.train_losses, self.val_losses)]
            })
            
            # ì €ì¥ ê²½ë¡œë“¤
            save_paths = [
                'training_losses.csv',
                os.path.join(os.path.expanduser('~'), 'training_losses.csv'),
                os.path.join(os.path.expanduser('~'), 'Desktop', 'training_losses.csv')
            ]
            
            for save_path in save_paths:
                try:
                    df.to_csv(save_path, index=False)
                    if os.path.exists(save_path):
                        print(f"âœ… ì†ì‹¤ ë°ì´í„° CSV ì €ì¥: '{save_path}'")
                        return save_path
                except:
                    continue
                    
            print("âš ï¸ CSV ì €ì¥ ì‹¤íŒ¨")
            return None
        except Exception as e:
            print(f"âŒ csv ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def create_simple_step_validation(self, model, test_loader, processor, num_samples=3):
        """ê°„ë‹¨í•œ step-by-step ê²€ì¦ ê·¸ë˜í”„ (ëŒ€ì•ˆ ë°©ë²•)"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            import os
            
            print("ğŸ¨ ê°„ë‹¨í•œ step-by-step ê²€ì¦ ê·¸ë˜í”„ ìƒì„±...")
            
            model.eval()
            
            # ê°„ë‹¨í•œ ë°©ë²•: ì—¬ëŸ¬ ê°œë³„ ì˜ˆì¸¡ì„ ì—°ê²°
            sample_states, sample_actions, sample_targets = next(iter(test_loader))
            
            # ì²« ëª‡ ê°œ ìƒ˜í”Œë¡œ ì—°ì† ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜
            predictions_list = []
            actuals_list = []
            
            with torch.no_grad():
                for i in range(min(num_samples, len(sample_states))):
                    # ê° ìƒ˜í”Œì— ëŒ€í•´ ì˜ˆì¸¡
                    pred = model(sample_states[i:i+1], sample_actions[i:i+1])
                    predictions_list.append(pred[0].numpy())
                    actuals_list.append(sample_targets[i].numpy())
            
            if len(predictions_list) == 0:
                print("âŒ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            predictions = np.array(predictions_list)
            actuals = np.array(actuals_list)
            
            # ì—­ì •ê·œí™”
            try:
                if hasattr(processor, 'state_scaler'):
                    pred_rescaled = processor.state_scaler.inverse_transform(predictions)
                    actual_rescaled = processor.state_scaler.inverse_transform(actuals)
                else:
                    pred_rescaled = predictions
                    actual_rescaled = actuals
            except Exception as e:
                print(f"âš ï¸ ì—­ì •ê·œí™” ì‹¤íŒ¨: {e}")
                pred_rescaled = predictions
                actual_rescaled = actuals
            
            # ìƒíƒœ ì´ë¦„ - Power ì œê±°
            state_dim = predictions.shape[1]
            if state_dim == 5:
                state_names = ['Tpip_in', 'Tpip_out', 'Tbdy', 'Tid', 'Tod']
            elif state_dim == 9:
                state_names = ['Tpip_in1', 'Tpip_in2', 'Tpip_out1', 'Tpip_out2', 
                              'Tbdy1', 'Tbdy2', 'Tid1', 'Tid2', 'Tod']
            else:
                state_names = [f'State_{i+1}' for i in range(state_dim)]
            
            # ê·¸ë˜í”„ ìƒì„± (ê°„ë‹¨í•œ ë²„ì „)
            n_features = min(6, state_dim)  # 6ê°œë§Œ í‘œì‹œ
            fig, axes = plt.subplots(2, 3, figsize=(15, 8))
            fig.suptitle(f'Simple Step-by-Step Validation (Auto IDë³„ 5ë¶„ ê°„ê²©, {num_samples} steps)', 
                        fontsize=14, fontweight='bold')
            
            axes_flat = axes.flatten()
            
            for i in range(n_features):
                ax = axes_flat[i]
                
                steps = range(len(pred_rescaled))
                true_vals = actual_rescaled[:, i]
                pred_vals = pred_rescaled[:, i]
                
                # ë‹¨ìˆœí•œ ë¼ì¸ í”Œë¡¯
                ax.plot(steps, true_vals, 'b-o', label='True', linewidth=2, markersize=6)
                ax.plot(steps, pred_vals, 'r-s', label='Predicted', linewidth=2, markersize=6)
                
                ax.set_title(f'{state_names[i]}', fontweight='bold')
                ax.set_xlabel('Step')
                ax.set_ylabel('Value')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                # MAE
                mae = np.mean(np.abs(pred_vals - true_vals))
                ax.text(0.05, 0.95, f'MAE: {mae:.3f}', transform=ax.transAxes,
                       bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
            
            plt.tight_layout()
            
            # ì €ì¥
            save_path = 'simple_step_validation.png'
            try:
                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
                if os.path.exists(save_path):
                    print(f"âœ… ê°„ë‹¨í•œ step-by-step ê·¸ë˜í”„ ì €ì¥: '{save_path}'")
                    return save_path
            except Exception as e:
                print(f"âŒ ê°„ë‹¨í•œ ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            plt.close()
            
        except Exception as e:
            print(f"âŒ ê°„ë‹¨í•œ step-by-step ê·¸ë˜í”„ ì˜¤ë¥˜: {e}")
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - Auto IDë³„ 5ë¶„ ê°„ê²© ìƒ˜í”Œë§ ìˆ˜ì • ë²„ì „"""
    
    # matplotlib ì„¤ì •
    try:
        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt
        plt.ioff()
        print("âœ… matplotlib ë°±ì—”ë“œ ì„¤ì • ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ matplotlib ì„¤ì • ë¬¸ì œ: {e}")
    
    print("ğŸ”¥ HVAC SSM World Model í›ˆë ¨ ì‹œì‘! (Auto IDë³„ 5ë¶„ ê°„ê²© ìƒ˜í”Œë§)")
    
    # 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    print("\n" + "="*50)
    print("ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
    print("="*50)
    
    processor = HVACDataProcessor()
    file_pattern = "../ê²½ë‚¨_ì‚¬ë¬´ì‹¤/LOG_SMARTCARE_*.csv"
    
    try:
        df = processor.load_data(file_pattern)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {df.shape}")
        
        # Auto IDë³„ ë°ì´í„° ë¶„í¬ í™•ì¸
        auto_id_counts = df['Auto Id'].value_counts().sort_index()
        print(f"ğŸ“Š Auto IDë³„ ë°ì´í„° ë¶„í¬ (5ë¶„ ê°„ê²© ë¦¬ìƒ˜í”Œë§ í›„):")
        for auto_id, count in auto_id_counts.items():
            print(f"   Auto ID {auto_id}: {count}ê°œ")
        
        # íŠ¹ì„± ì¶”ì¶œ
        states, actions, file_sources = processor.extract_features(df)
        print(f"âœ… íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ")
        print(f"   States: {states.shape}")
        print(f"   Actions: {actions.shape}")
        
        # ì‹œí€€ìŠ¤ ìƒì„± (Auto IDë³„ ë…ë¦½ì )
        seq_length = 10
        X_states, X_actions, y_states = processor.create_sequences_per_auto_id(
            states, actions, file_sources, seq_length
        )
        print(f"âœ… ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ (Auto IDë³„ ë…ë¦½ì )")
        print(f"   X_states: {X_states.shape}")
        print(f"   X_actions: {X_actions.shape}")
        print(f"   y_states: {y_states.shape}")
        
    except Exception as e:
        print(f"âš ï¸ ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ë”ë¯¸ ë°ì´í„°ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
        
        # ë”ë¯¸ ë°ì´í„° ìƒì„± (Auto IDë³„ë¡œ êµ¬ë¶„) - Power ì œê±°
        n_auto_ids = 6  # Auto ID 0~5
        n_samples_per_id = 1000
        seq_length = 10
        
        np.random.seed(42)
        
        all_states = []
        all_actions = []
        all_file_sources = []
        
        for auto_id in range(n_auto_ids):
            # Auto IDë³„ë¡œ ì•½ê°„ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§„ ë”ë¯¸ ë°ì´í„°
            base_temp = 25 + np.random.randn(n_samples_per_id) * 3 + auto_id * 0.5
            
            states = np.column_stack([
                base_temp + np.random.randn(n_samples_per_id) * 1,  # Tpip_in
                base_temp + np.random.randn(n_samples_per_id) * 1,  # Tpip_out  
                base_temp + np.random.randn(n_samples_per_id) * 0.5,  # Tbdy
                base_temp + np.random.randn(n_samples_per_id) * 2,  # Tid
                base_temp + 5 + np.sin(np.arange(n_samples_per_id) * 0.01) * 3  # Tod (Power ì œê±°)
            ])
            
            tcon = 22 + np.random.randn(n_samples_per_id) * 2
            on_off = (np.abs(tcon - states[:, 3]) > 1).astype(int)
            ptarget = 20 + 5.0 + np.random.randn(n_samples_per_id) * 1  # Power ì—†ìœ¼ë¯€ë¡œ ê³ ì •ê°’ ì‚¬ìš©
            
            actions = np.column_stack([tcon, on_off, ptarget])
            
            file_sources = np.repeat(f'dummy_file_AutoID_{auto_id}', n_samples_per_id)
            
            all_states.append(states)
            all_actions.append(actions)
            all_file_sources.append(file_sources)
            
            print(f"   Auto ID {auto_id}: State ì°¨ì› {states.shape[1]}ê°œ (Power ì œì™¸)")
        
        # ëª¨ë“  Auto ID ë°ì´í„° ê²°í•©
        states = np.vstack(all_states)
        actions = np.vstack(all_actions)
        file_sources = np.concatenate(all_file_sources)
        
        processor = HVACDataProcessor()
        X_states, X_actions, y_states = processor.create_sequences_per_auto_id(
            states, actions, file_sources, seq_length
        )
        
        print(f"âœ… ë”ë¯¸ ë°ì´í„° ìƒì„± ì™„ë£Œ (Auto IDë³„ êµ¬ë¶„)")
        print(f"   Auto ID ê°œìˆ˜: {n_auto_ids}")
        print(f"   ê° Auto IDë‹¹ ìƒ˜í”Œ: {n_samples_per_id}")
        print(f"   X_states: {X_states.shape}")
        print(f"   X_actions: {X_actions.shape}")
        print(f"   y_states: {y_states.shape}")
    
    # 2. ë°ì´í„°ì…‹ ë¶„í• 
    print("\n" + "="*50)
    print("ğŸ”„ ë°ì´í„°ì…‹ ë¶„í• ")
    print("="*50)
    
    X_states_train, X_states_test, X_actions_train, X_actions_test, y_states_train, y_states_test = train_test_split(
        X_states, X_actions, y_states, test_size=0.2, random_state=42
    )
    
    X_states_train, X_states_val, X_actions_train, X_actions_val, y_states_train, y_states_val = train_test_split(
        X_states_train, X_actions_train, y_states_train, test_size=0.25, random_state=42
    )
    
    print(f"âœ… ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ")
    print(f"   í›ˆë ¨: {len(X_states_train)}ê°œ")
    print(f"   ê²€ì¦: {len(X_states_val)}ê°œ") 
    print(f"   í…ŒìŠ¤íŠ¸: {len(X_states_test)}ê°œ")
    
    # 3. ë°ì´í„° ë¡œë” ìƒì„±
    batch_size = 32
    
    train_dataset = HVACDataset(X_states_train, X_actions_train, y_states_train)
    val_dataset = HVACDataset(X_states_val, X_actions_val, y_states_val)
    test_dataset = HVACDataset(X_states_test, X_actions_test, y_states_test)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)
    test_loader = DataLoader(test_dataset, batch_size=batch_size)
    
    # 4. ëª¨ë¸ ìƒì„±
    print("\n" + "="*50)
    print("ğŸ¤– ëª¨ë¸ ìƒì„±")
    print("="*50)
    
    state_dim = X_states.shape[-1]
    action_dim = X_actions.shape[-1]
    
    model = SimpleSSMWorldModel(
        state_dim=state_dim,
        action_dim=action_dim,
        hidden_dim=32,
        latent_dim=16
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
    print(f"   State dim: {state_dim}")
    print(f"   Action dim: {action_dim}")
    print(f"   ì´ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
    print(f"   ëª¨ë¸ í¬ê¸°: ~{total_params * 4 / 1024:.1f}KB")
    
    # 5. ëª¨ë¸ í›ˆë ¨
    print("\n" + "="*50)
    print("ğŸ¯ ëª¨ë¸ í›ˆë ¨")
    print("="*50)
    
    trainer = SSMTrainer(model, learning_rate=0.003)
    
    results = trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=200,
        patience=10
    )
    
    # 6. ê²°ê³¼ ì‹œê°í™”
    print("\n" + "="*50)
    print("ğŸ“ˆ ê²°ê³¼ ì‹œê°í™”")
    print("="*50)
    
    # ê·¸ë˜í”„ ì €ì¥ ì‹œë„
    trainer.plot_losses()
    
    # CSVë¡œë„ ì €ì¥ (ì•ˆì „í•œ í˜¸ì¶œ)
    try:
        csv_path = trainer.save_losses_to_csv()
        if csv_path:
            print(f"ğŸ“Š CSV ë°ì´í„°ë„ ì €ì¥ë¨: {csv_path}")
    except Exception as e:
        print(f"âš ï¸ CSV ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        csv_path = None
    
    # ì‹œê°í™” ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì¶”ê°€ ë°©ë²•ë“¤
    print("\nğŸ”§ ì‹œê°í™” ë¬¸ì œ í•´ê²° ë°©ë²•:")
    print("1. í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ 'training_progress.png' íŒŒì¼ í™•ì¸")
    print("2. ë°”íƒ•í™”ë©´ì—ì„œ 'training_progress.png' íŒŒì¼ í™•ì¸") 
    print("3. ì‹œìŠ¤í…œ ì„ì‹œ í´ë”ì—ì„œ íŒŒì¼ í™•ì¸")
    if csv_path:
        print(f"4. CSV ë°ì´í„° íŒŒì¼: {csv_path}")
    
    # ì†ì‹¤ ë°ì´í„° ì½˜ì†” ì¶œë ¥
    print(f"\nğŸ“Š í›ˆë ¨ ì§„í–‰ ìƒí™©:")
    print(f"   ì´ ì—í¬í¬: {len(results['train_losses'])}")
    print(f"   ìµœì¢… í›ˆë ¨ ì†ì‹¤: {results['train_losses'][-1]:.6f}")
    print(f"   ìµœì¢… ê²€ì¦ ì†ì‹¤: {results['val_losses'][-1]:.6f}")
    print(f"   ìµœì¢… Gap: {results['val_losses'][-1] - results['train_losses'][-1]:.6f}")
    
    # ê°„ë‹¨í•œ ASCII ê·¸ë˜í”„ ìƒì„±
    print(f"\nğŸ“ˆ ì†ì‹¤ ì¶”ì´ (ASCII):")
    train_losses = results['train_losses']
    val_losses = results['val_losses']
    
    # ìµœê·¼ 10ê°œ ì—í¬í¬ë§Œ í‘œì‹œ
    recent_epochs = min(10, len(train_losses))
    print(f"   ìµœê·¼ {recent_epochs}ê°œ ì—í¬í¬:")
    
    for i in range(len(train_losses) - recent_epochs, len(train_losses)):
        epoch = i + 1
        train_loss = train_losses[i]
        val_loss = val_losses[i]
        
        # ê°„ë‹¨í•œ ë°” í‘œì‹œ (0-1 ìŠ¤ì¼€ì¼)
        max_loss = max(max(train_losses), max(val_losses))
        train_bar = int((train_loss / max_loss) * 20)
        val_bar = int((val_loss / max_loss) * 20)
        
        print(f"   Epoch {epoch:2d}: Train {'â–ˆ' * train_bar:<20} {train_loss:.4f}")
        print(f"            Val   {'â–ˆ' * val_bar:<20} {val_loss:.4f}")
        print("")
    
    # 7. í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í‰ê°€ ë° ê²€ì¦ ê·¸ë˜í”„
    print("\n" + "="*50)
    print("ğŸ” ëª¨ë¸ ê²€ì¦ ë° ì„±ëŠ¥ í‰ê°€")
    print("="*50)
    
    test_loss = trainer.validate(test_loader)
    print(f"âœ… ìµœì¢… í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.6f}")
    
    # ê²€ì¦ ê·¸ë˜í”„ ìƒì„±
    print("\nğŸ“Š ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
    
    try:
        # 1. Step-by-step ì˜ˆì¸¡ ê²€ì¦ (ì´ë¯¸ì§€ì™€ ê°™ì€ ìŠ¤íƒ€ì¼)
        trainer.create_validation_plots(model, test_loader, processor, num_steps=10)
        print("âœ… Step-by-step ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ Step-by-step ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ëŒ€ì•ˆ: ê°„ë‹¨í•œ step-by-step ê·¸ë˜í”„ ìƒì„±
        try:
            print("ğŸ”„ ê°„ë‹¨í•œ step-by-step ê·¸ë˜í”„ ìƒì„± ì‹œë„...")
            trainer.create_simple_step_validation(model, test_loader, processor)
        except Exception as e2:
            print(f"âš ï¸ ê°„ë‹¨í•œ ê²€ì¦ ê·¸ë˜í”„ë„ ì‹¤íŒ¨: {e2}")
    
    try:
        # 2. ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ vs ì‹¤ì œ (Bar chart ìŠ¤íƒ€ì¼)  
        trainer.create_single_step_validation(model, test_loader, processor, num_samples=5)
        print("âœ… ë‹¨ì¼ ìŠ¤í… ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ ë‹¨ì¼ ìŠ¤í… ê²€ì¦ ê·¸ë˜í”„ ìƒì„± ì‹¤íŒ¨: {e}")
    
    print("ğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤:")
    print("   - training_progress.png: í›ˆë ¨ ê³¼ì • ê·¸ë˜í”„")
    print("   - step_by_step_validation.png: ì—°ì† ì˜ˆì¸¡ ê²€ì¦")
    print("   - single_step_validation.png: ë‹¨ì¼ ìŠ¤í… ì˜ˆì¸¡ ê²€ì¦")
    if csv_path:
        print(f"   - {os.path.basename(csv_path)}: ì†ì‹¤ ë°ì´í„° CSV")
    
    # ì¶”ê°€: ìˆ˜ë™ ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜
    def create_manual_plot():
        """ìˆ˜ë™ìœ¼ë¡œ ê·¸ë˜í”„ ìƒì„± ë° ì €ì¥"""
        try:
            import matplotlib
            matplotlib.use('Agg')
            import matplotlib.pyplot as plt
            
            # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì— ì €ì¥
            current_dir = os.getcwd()
            save_path = os.path.join(current_dir, 'hvac_training_results.png')
            
            print(f"ğŸ¨ ìˆ˜ë™ ê·¸ë˜í”„ ìƒì„± ì¤‘... ì €ì¥ ê²½ë¡œ: {save_path}")
            
            fig, axes = plt.subplots(2, 1, figsize=(12, 8))
            
            # í›ˆë ¨/ê²€ì¦ ì†ì‹¤
            axes[0].plot(range(1, len(train_losses)+1), train_losses, 'b-o', label='Training Loss', markersize=4)
            axes[0].plot(range(1, len(val_losses)+1), val_losses, 'r-s', label='Validation Loss', markersize=4)
            axes[0].set_xlabel('Epoch')
            axes[0].set_ylabel('Loss')
            axes[0].set_title('HVAC SSM Training Progress (Auto IDë³„ 5ë¶„ ê°„ê²©)', fontweight='bold')
            axes[0].legend()
            axes[0].grid(True, alpha=0.3)
            axes[0].set_yscale('log')
            
            # Gap ë¶„ì„
            gaps = [v - t for t, v in zip(train_losses, val_losses)]
            axes[1].plot(range(1, len(gaps)+1), gaps, 'orange', linewidth=2, marker='^', markersize=4)
            axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.7)
            axes[1].set_xlabel('Epoch')
            axes[1].set_ylabel('Validation - Training Loss')
            axes[1].set_title('Overfitting Monitor', fontweight='bold')
            axes[1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì‹œë„
            formats = ['png', 'pdf', 'svg']
            for fmt in formats:
                try:
                    file_path = save_path.replace('.png', f'.{fmt}')
                    plt.savefig(file_path, format=fmt, dpi=300, bbox_inches='tight')
                    if os.path.exists(file_path):
                        print(f"âœ… ê·¸ë˜í”„ ì €ì¥ ì„±ê³µ: {file_path}")
                        break
                except Exception as e:
                    print(f"âš ï¸ {fmt} ì €ì¥ ì‹¤íŒ¨: {e}")
            
            plt.close()
            
        except Exception as e:
            print(f"âŒ ìˆ˜ë™ ê·¸ë˜í”„ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # ìˆ˜ë™ ê·¸ë˜í”„ ìƒì„± ì‹œë„
    if len(results['train_losses']) > 0:
        create_manual_plot()
    
    # 8. ì˜ˆì¸¡ ì˜ˆì‹œ (ì½˜ì†” ì¶œë ¥)
    print("\n" + "="*50)
    print("ğŸ”® ì˜ˆì¸¡ ì˜ˆì‹œ")
    print("="*50)
    
    model.eval()
    with torch.no_grad():
        sample_states, sample_actions, sample_targets = next(iter(test_loader))
        predictions = model(sample_states[:3], sample_actions[:3])
        
        print("ì˜ˆì¸¡ vs ì‹¤ì œ (ì •ê·œí™”ëœ ê°’, ì²« 3ê°œ ìƒ˜í”Œ):")
        for i in range(3):
            pred = predictions[i].numpy()
            target = sample_targets[i].numpy()
            error = np.abs(pred - target)
            
            print(f"\nìƒ˜í”Œ {i+1}:")
            print(f"  ì˜ˆì¸¡ê°’: [{pred[0]:.3f}, {pred[1]:.3f}, {pred[2]:.3f}...] (ì´ {len(pred)}ê°œ)")
            print(f"  ì‹¤ì œê°’: [{target[0]:.3f}, {target[1]:.3f}, {target[2]:.3f}...] (ì´ {len(target)}ê°œ)")
            print(f"  ìµœëŒ€ì˜¤ì°¨: {np.max(error):.4f}")
    
    # 9. ê°•í™”í•™ìŠµ í†µí•© ê°€ì´ë“œ
    print("\n" + "="*60)
    print("ğŸ® ê°•í™”í•™ìŠµ í†µí•© ê°€ì´ë“œ (Auto IDë³„ 5ë¶„ ê°„ê²© ë°ì´í„° ê¸°ë°˜)")
    print("="*60)
    
    class HVACEnvironmentModel:
        def __init__(self, world_model, state_scaler, action_scaler):
            self.world_model = world_model
            self.state_scaler = state_scaler
            self.action_scaler = action_scaler
            
        def predict_next_state(self, current_state, action):
            # ì •ê·œí™”
            state_norm = self.state_scaler.transform(current_state.reshape(1, -1))[0]
            action_norm = self.action_scaler.transform(action.reshape(1, -1))[0]
            
            # ì˜ˆì¸¡
            next_state_norm = self.world_model.predict_next_state(
                torch.FloatTensor(state_norm), 
                torch.FloatTensor(action_norm)
            ).numpy()
            
            # ì—­ì •ê·œí™”
            next_state = self.state_scaler.inverse_transform(next_state_norm.reshape(1, -1))[0]
            return next_state
            
        def calculate_reward(self, state, action, next_state):
            # ê°œì„ ëœ ë³´ìƒ í•¨ìˆ˜ (5ë¶„ ê°„ê²© ë°ì´í„° ê³ ë ¤, Power ì œì™¸)
            if len(state) >= 4:
                temp_error = abs(next_state[3] - action[0])  # ëª©í‘œì˜¨ë„ì™€ì˜ ì°¨ì´ (Tid vs Tcon)
                
                # 5ë¶„ ê°„ê²©ì´ë¯€ë¡œ ë³€í™”ìœ¨ ê³ ë ¤
                temp_change_rate = abs(next_state[3] - state[3]) / 5.0  # ë¶„ë‹¹ ì˜¨ë„ ë³€í™”ìœ¨
                stability_bonus = -temp_change_rate if temp_change_rate > 1.0 else 0.1
                
                # ë°°ê´€ ì˜¨ë„ íš¨ìœ¨ì„± (Tpip_in, Tpip_out ê´€ê³„)
                pipe_efficiency = -abs(next_state[0] - next_state[1])  # ë°°ê´€ ì˜¨ë„ì°¨ê°€ ì ì„ìˆ˜ë¡ íš¨ìœ¨ì 
                
                reward = -temp_error + stability_bonus + pipe_efficiency * 0.1
            else:
                reward = -np.mean(np.abs(next_state - state))
            
            return reward
    
    env_model = HVACEnvironmentModel(model, processor.state_scaler, processor.action_scaler)
    
    print("âœ… ê°•í™”í•™ìŠµ í™˜ê²½ ëª¨ë¸ ìƒì„± ì™„ë£Œ (5ë¶„ ê°„ê²© ë°ì´í„° ê¸°ë°˜)")
    print("\nğŸ¯ ì£¼ìš” ê°œì„ ì‚¬í•­:")
    print("- Auto IDë³„ë¡œ ë…ë¦½ì ì¸ 5ë¶„ ê°„ê²© ë°ì´í„° ì‚¬ìš©")
    print("- Power ì œì™¸: ì¸¡ì • ì£¼ê¸°ê°€ ë‹¬ë¼ World Modelì—ì„œ ì œì™¸")
    print("- ì˜¨ë„ ì¤‘ì‹¬ì˜ ë³´ìƒ í•¨ìˆ˜: ë°°ê´€ íš¨ìœ¨ì„± ë° ì•ˆì •ì„± ê³ ë ¤")
    print("- ì‹¤ì œ ì—ì–´ì»¨ ìš´ì˜ íŒ¨í„´ ë°˜ì˜")
    
    print(f"\nğŸ“Š ìµœì¢… ì„±ëŠ¥ ìš”ì•½:")
    print(f"   ìµœì¢… ê²€ì¦ ì†ì‹¤: {results['best_val_loss']:.6f}")
    print(f"   ìµœì¢… í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.6f}")
    print(f"   ëª¨ë¸ íŒŒë¼ë¯¸í„°: {total_params:,}ê°œ")
    
    return {
        'best_val_loss': results['best_val_loss'],
        'test_loss': test_loss,
        'model_size_kb': total_params * 4 / 1024,
        'total_params': total_params
    }

if __name__ == "__main__":
    try:
        performance_metrics = main()
        print(f"\nğŸ‰ í”„ë¡œê·¸ë¨ ì™„ë£Œ! (Auto IDë³„ 5ë¶„ ê°„ê²© ìƒ˜í”Œë§)")
        print(f"   Test Loss: {performance_metrics['test_loss']:.6f}")
        print(f"   Model Size: {performance_metrics['model_size_kb']:.1f}KB")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()